{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcb8f3c",
   "metadata": {},
   "source": [
    "# Crawl dataset with all submissions info\n",
    "OpenReview Venue Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15b9499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aganap12/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-17 12:22:54.567366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 12:23:01.152658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import fitz\n",
    "import io\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba524d57",
   "metadata": {},
   "source": [
    "## Crawl list of all submissions\n",
    "Here we scrape the _notes_ , (list of all submissions) using OpenReview's API, way faster than Selenium-based scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d02c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "venue = 'ICLR.cc/2023/Conference'\n",
    "venue_short = 'iclr2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a451ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conference_notes(venue, blind_submission=False):\n",
    "    \"\"\"\n",
    "    Get all notes of a conference (data) from OpenReview API.\n",
    "    If results are not final, you should set blind_submission=True.\n",
    "    \"\"\"\n",
    "\n",
    "    blind_param = '-/Blind_Submission' if blind_submission else ''\n",
    "    offset = 0\n",
    "    notes = []\n",
    "    while True:\n",
    "        print('Offset:', offset, 'Data:', len(notes))\n",
    "        url = f'https://api.openreview.net/notes?invitation={venue}/{blind_param}&offset={offset}'\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if len(data['notes']) == 0:\n",
    "            break\n",
    "        offset += 1000\n",
    "        notes.extend(data['notes'])\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6974ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset: 0 Data: 0\n",
      "Offset: 1000 Data: 1000\n",
      "Offset: 2000 Data: 2000\n",
      "Offset: 3000 Data: 3000\n",
      "Offset: 4000 Data: 3798\n",
      "Number of submissions: 3798\n"
     ]
    }
   ],
   "source": [
    "raw_notes = get_conference_notes(venue, blind_submission=True)\n",
    "print(\"Number of submissions:\", len(raw_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d074dc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>number</th>\n",
       "      <th>cdate</th>\n",
       "      <th>mdate</th>\n",
       "      <th>ddate</th>\n",
       "      <th>tcdate</th>\n",
       "      <th>tmdate</th>\n",
       "      <th>tddate</th>\n",
       "      <th>forum</th>\n",
       "      <th>...</th>\n",
       "      <th>content.student_author</th>\n",
       "      <th>content.Please_choose_the_closest_area_that_your_submission_falls_into</th>\n",
       "      <th>content.paperhash</th>\n",
       "      <th>content.pdf</th>\n",
       "      <th>content.supplementary_material</th>\n",
       "      <th>content._bibtex</th>\n",
       "      <th>content.venue</th>\n",
       "      <th>content.venueid</th>\n",
       "      <th>content.TL;DR</th>\n",
       "      <th>content.community_implementations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>pmo4AKuE4-p</td>\n",
       "      <td>6620</td>\n",
       "      <td>1663850590815</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850590815</td>\n",
       "      <td>1677758485903</td>\n",
       "      <td>None</td>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Social Aspects of Machine Learning (eg, AI saf...</td>\n",
       "      <td>adebayo|quantifying_and_mitigating_the_impact_...</td>\n",
       "      <td>/pdf/8fa4751c3b6bc13a0eefd3b9a9dd75dc9359f20f.pdf</td>\n",
       "      <td>/attachment/151652f4d981a49f9dfa81be992839a243...</td>\n",
       "      <td>@inproceedings{\\nadebayo2023quantifying,\\ntitl...</td>\n",
       "      <td>ICLR 2023 poster</td>\n",
       "      <td>ICLR.cc/2023/Conference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>kVYulJycT2K</td>\n",
       "      <td>6611</td>\n",
       "      <td>1663850589829</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850589829</td>\n",
       "      <td>1676330777348</td>\n",
       "      <td>None</td>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Deep Learning and representational learning</td>\n",
       "      <td>zhuang|suppression_helps_lateral_inhibitionins...</td>\n",
       "      <td>/pdf/bc66a3bbb804a7158ba77a4de9f91a196e8eaf9a.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@misc{\\nzhuang2023suppression,\\ntitle={Suppres...</td>\n",
       "      <td>Submitted to ICLR 2023</td>\n",
       "      <td>ICLR.cc/2023/Conference</td>\n",
       "      <td>Improving feature learning with lateral inhibi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>RAIF4RUF0T</td>\n",
       "      <td>6610</td>\n",
       "      <td>1663850589709</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850589709</td>\n",
       "      <td>1710206488222</td>\n",
       "      <td>None</td>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Machine Learning for Sciences (eg biology, phy...</td>\n",
       "      <td>tran|factorized_fourier_neural_operators</td>\n",
       "      <td>/pdf/c381fdf1b7600bdbaba7b4a98c1679006ec61c83.pdf</td>\n",
       "      <td></td>\n",
       "      <td>@inproceedings{\\ntran2023factorized,\\ntitle={F...</td>\n",
       "      <td>ICLR 2023 poster</td>\n",
       "      <td>ICLR.cc/2023/Conference</td>\n",
       "      <td>An efficient and scalable neural PDE solver us...</td>\n",
       "      <td>[![CatalyzeX](/images/catalyzex_icon.svg) 1 co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>ix_LR-W0OM2</td>\n",
       "      <td>6603</td>\n",
       "      <td>1663850588877</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850588877</td>\n",
       "      <td>1677757114293</td>\n",
       "      <td>None</td>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Deep Learning and representational learning</td>\n",
       "      <td>narshana|dfpc_data_flow_driven_pruning_of_coup...</td>\n",
       "      <td>/pdf/a04d739740d3a54486c4a47bf7d26dd24b41732d.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@inproceedings{\\nnarshana2023dfpc,\\ntitle={{DF...</td>\n",
       "      <td>ICLR 2023 poster</td>\n",
       "      <td>ICLR.cc/2023/Conference</td>\n",
       "      <td>We propose a novel data-free algorithm to acce...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sZI1Oj9KBKy</td>\n",
       "      <td>vRziu1jJDu</td>\n",
       "      <td>6601</td>\n",
       "      <td>1663850588630</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850588630</td>\n",
       "      <td>1677757168918</td>\n",
       "      <td>None</td>\n",
       "      <td>sZI1Oj9KBKy</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Deep Learning and representational learning</td>\n",
       "      <td>murti|tvsprune_pruning_nondiscriminative_filte...</td>\n",
       "      <td>/pdf/54b7911797398691422146138209e69d0674e5de.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@inproceedings{\\nmurti2023tvsprune,\\ntitle={{T...</td>\n",
       "      <td>ICLR 2023 poster</td>\n",
       "      <td>ICLR.cc/2023/Conference</td>\n",
       "      <td>We use the total variation distance between th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     original  number          cdate mdate ddate         tcdate  \\\n",
       "0  RUzSobdYy0V  pmo4AKuE4-p    6620  1663850590815  None  None  1663850590815   \n",
       "1  N3kGYG3ZcTi  kVYulJycT2K    6611  1663850589829  None  None  1663850589829   \n",
       "2  tmIiMPl4IPa   RAIF4RUF0T    6610  1663850589709  None  None  1663850589709   \n",
       "3  mhnHqRqcjYU  ix_LR-W0OM2    6603  1663850588877  None  None  1663850588877   \n",
       "4  sZI1Oj9KBKy   vRziu1jJDu    6601  1663850588630  None  None  1663850588630   \n",
       "\n",
       "          tmdate tddate        forum  ... content.student_author  \\\n",
       "0  1677758485903   None  RUzSobdYy0V  ...                          \n",
       "1  1676330777348   None  N3kGYG3ZcTi  ...                          \n",
       "2  1710206488222   None  tmIiMPl4IPa  ...                          \n",
       "3  1677757114293   None  mhnHqRqcjYU  ...                          \n",
       "4  1677757168918   None  sZI1Oj9KBKy  ...                          \n",
       "\n",
       "  content.Please_choose_the_closest_area_that_your_submission_falls_into  \\\n",
       "0  Social Aspects of Machine Learning (eg, AI saf...                       \n",
       "1        Deep Learning and representational learning                       \n",
       "2  Machine Learning for Sciences (eg biology, phy...                       \n",
       "3        Deep Learning and representational learning                       \n",
       "4        Deep Learning and representational learning                       \n",
       "\n",
       "                                   content.paperhash  \\\n",
       "0  adebayo|quantifying_and_mitigating_the_impact_...   \n",
       "1  zhuang|suppression_helps_lateral_inhibitionins...   \n",
       "2           tran|factorized_fourier_neural_operators   \n",
       "3  narshana|dfpc_data_flow_driven_pruning_of_coup...   \n",
       "4  murti|tvsprune_pruning_nondiscriminative_filte...   \n",
       "\n",
       "                                         content.pdf  \\\n",
       "0  /pdf/8fa4751c3b6bc13a0eefd3b9a9dd75dc9359f20f.pdf   \n",
       "1  /pdf/bc66a3bbb804a7158ba77a4de9f91a196e8eaf9a.pdf   \n",
       "2  /pdf/c381fdf1b7600bdbaba7b4a98c1679006ec61c83.pdf   \n",
       "3  /pdf/a04d739740d3a54486c4a47bf7d26dd24b41732d.pdf   \n",
       "4  /pdf/54b7911797398691422146138209e69d0674e5de.pdf   \n",
       "\n",
       "                      content.supplementary_material  \\\n",
       "0  /attachment/151652f4d981a49f9dfa81be992839a243...   \n",
       "1                                                NaN   \n",
       "2                                                      \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                     content._bibtex           content.venue  \\\n",
       "0  @inproceedings{\\nadebayo2023quantifying,\\ntitl...        ICLR 2023 poster   \n",
       "1  @misc{\\nzhuang2023suppression,\\ntitle={Suppres...  Submitted to ICLR 2023   \n",
       "2  @inproceedings{\\ntran2023factorized,\\ntitle={F...        ICLR 2023 poster   \n",
       "3  @inproceedings{\\nnarshana2023dfpc,\\ntitle={{DF...        ICLR 2023 poster   \n",
       "4  @inproceedings{\\nmurti2023tvsprune,\\ntitle={{T...        ICLR 2023 poster   \n",
       "\n",
       "           content.venueid                                      content.TL;DR  \\\n",
       "0  ICLR.cc/2023/Conference                                                NaN   \n",
       "1  ICLR.cc/2023/Conference  Improving feature learning with lateral inhibi...   \n",
       "2  ICLR.cc/2023/Conference  An efficient and scalable neural PDE solver us...   \n",
       "3  ICLR.cc/2023/Conference  We propose a novel data-free algorithm to acce...   \n",
       "4  ICLR.cc/2023/Conference  We use the total variation distance between th...   \n",
       "\n",
       "                   content.community_implementations  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  [![CatalyzeX](/images/catalyzex_icon.svg) 1 co...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.json_normalize(raw_notes)\n",
    "df_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1de767e9",
   "metadata": {},
   "source": [
    "## (optional) older crawled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c02af",
   "metadata": {},
   "source": [
    "## Crawl forums of each submission\n",
    "Here we scrape the forums of each submissions, it can be pretty fast thanks to:\n",
    "- OpenReview's API (we use requests)\n",
    "- Multiprocessing to parallelize the scraping of each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139f9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiprocessing pool of requests over index of dataframe\n",
    "\n",
    "extra = \"trash=true&details=replyCount%2Cwritable%2Crevisions%2Coriginal%2Coverwriting%2Cinvitation%2Ctags\"\n",
    "\n",
    "def get_paper_data(paper_id, extra='', timeout=5):\n",
    "    try:\n",
    "        url = f\"https://api.openreview.net/notes?forum={paper_id}&{extra}\"\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error for paper {paper_id}: Request timed out\")\n",
    "        return None\n",
    "    except:\n",
    "        print(f\"Error for paper {paper_id}: General error\")\n",
    "        return None\n",
    "\n",
    "def retry_get_paper_data(paper_id, extra='', timeout=5, retries=10):\n",
    "    for i in range(retries):\n",
    "        data = get_paper_data(paper_id, extra, timeout)\n",
    "        if data is not None:\n",
    "            return data\n",
    "    print(f\"Error for paper {paper_id}: All {retries} attempts failed\")\n",
    "    return None\n",
    "\n",
    "def get_paper_data_multi(paper_ids, ratio=0.8):\n",
    "    num_processes = int(ratio*mp.cpu_count())\n",
    "    with Pool(num_processes) as p:\n",
    "        data = list(tqdm(p.imap(retry_get_paper_data, paper_ids), total=len(paper_ids)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969f4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content.title</th>\n",
       "      <th>content.keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>Quantifying and Mitigating the Impact of Label...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>Suppression helps: Lateral Inhibition-inspired...</td>\n",
       "      <td>[Lateral Inhibition, Convolutional Neural Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>Factorized Fourier Neural Operators</td>\n",
       "      <td>[fourier transform, fourier operators, pde, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>DFPC: Data flow driven pruning of coupled chan...</td>\n",
       "      <td>[Pruning, Data Free, Model Compression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sZI1Oj9KBKy</td>\n",
       "      <td>TVSPrune - Pruning Non-discriminative filters ...</td>\n",
       "      <td>[Structured pruning, model compression]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      content.title  \\\n",
       "0  RUzSobdYy0V  Quantifying and Mitigating the Impact of Label...   \n",
       "1  N3kGYG3ZcTi  Suppression helps: Lateral Inhibition-inspired...   \n",
       "2  tmIiMPl4IPa                Factorized Fourier Neural Operators   \n",
       "3  mhnHqRqcjYU  DFPC: Data flow driven pruning of coupled chan...   \n",
       "4  sZI1Oj9KBKy  TVSPrune - Pruning Non-discriminative filters ...   \n",
       "\n",
       "                                    content.keywords  \n",
       "0                                                 []  \n",
       "1  [Lateral Inhibition, Convolutional Neural Netw...  \n",
       "2  [fourier transform, fourier operators, pde, na...  \n",
       "3            [Pruning, Data Free, Model Compression]  \n",
       "4            [Structured pruning, model compression]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter df with only id, title, url and keywords\n",
    "df_raw_filtered = df_raw[['id', 'content.title', 'content.keywords']]\n",
    "df_raw_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7a42c1-7d3a-4e95-9ae9-9234d9d3e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3013615/3332096888.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_raw_filtered['pdf-url'] = \"https://openreview.net/pdf?id=\" + df_raw_filtered[\"id\"]\n"
     ]
    }
   ],
   "source": [
    "df_raw_filtered['pdf-url'] = \"https://openreview.net/pdf?id=\" + df_raw_filtered[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1573a564-02fe-4693-b339-09608c861072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https://openreview.net/pdf?id=RUzSobdYy0V\n",
       "1       https://openreview.net/pdf?id=N3kGYG3ZcTi\n",
       "2       https://openreview.net/pdf?id=tmIiMPl4IPa\n",
       "3       https://openreview.net/pdf?id=mhnHqRqcjYU\n",
       "4       https://openreview.net/pdf?id=sZI1Oj9KBKy\n",
       "                          ...                    \n",
       "3793     https://openreview.net/pdf?id=P5Z-Zl9XJ7\n",
       "3794     https://openreview.net/pdf?id=IJwhRE510b\n",
       "3795     https://openreview.net/pdf?id=4XMAzZasId\n",
       "3796    https://openreview.net/pdf?id=ED2Jjms9A4H\n",
       "3797     https://openreview.net/pdf?id=jU-AXLS2bl\n",
       "Name: pdf-url, Length: 3798, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_filtered['pdf-url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bd4ea7b-036c-40b1-bb82-6ad99403541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(paper_url):\n",
    "    response = requests.get(paper_url)\n",
    "    pdf_content = response.content\n",
    "    text = \"\"\n",
    "    with fitz.open(stream=io.BytesIO(pdf_content)) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39035252-128c-4761-ab92-2ae8a596e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tagged_data = []\n",
    "    return word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5af727-ae89-4a9e-ac54-b74cebd66c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from replicate.client import Client\n",
    "\n",
    "replicate = Client(api_token=\"r8_IbZu0U3qUJ5ZC0TzzMm6xCJ6yU5UxVi16Ejo4\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./iclr-chromadb-client\")\n",
    "collection = client.get_or_create_collection(\"iclr2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb95e006-4484-4691-ab85-836212a4c3c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m df_raw_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf-url\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     pdf_text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     preprocessed_text \u001b[38;5;241m=\u001b[39m preprocess_text(pdf_text)\n\u001b[1;32m      6\u001b[0m     tagged_data\u001b[38;5;241m.\u001b[39mappend(TaggedDocument(words\u001b[38;5;241m=\u001b[39mpreprocessed_text, tags\u001b[38;5;241m=\u001b[39m[url]))\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(paper_url)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fitz\u001b[38;5;241m.\u001b[39mopen(stream\u001b[38;5;241m=\u001b[39mio\u001b[38;5;241m.\u001b[39mBytesIO(pdf_content)) \u001b[38;5;28;01mas\u001b[39;00m doc:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[0;32m----> 7\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pymupdf/utils.py:803\u001b[0m, in \u001b[0;36mget_text\u001b[0;34m(page, option, clip, flags, textpage, sort, delimiters)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m#pymupdf.exception_info()\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 803\u001b[0m     tp \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(tp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m page:\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot a textpage of this page\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pymupdf/__init__.py:9260\u001b[0m, in \u001b[0;36mPage.get_textpage\u001b[0;34m(self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m   9258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_rotation(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   9259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 9260\u001b[0m     textpage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9261\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   9262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m old_rotation \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pymupdf/__init__.py:7782\u001b[0m, in \u001b[0;36mPage._get_textpage\u001b[0;34m(self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m   7780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_textpage\u001b[39m(\u001b[38;5;28mself\u001b[39m, clip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   7781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g_use_extra:\n\u001b[0;32m-> 7782\u001b[0m         ll_tpage \u001b[38;5;241m=\u001b[39m \u001b[43mextra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7783\u001b[0m         tpage \u001b[38;5;241m=\u001b[39m mupdf\u001b[38;5;241m.\u001b[39mFzStextPage(ll_tpage)\n\u001b[1;32m   7784\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tpage\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pymupdf/extra.py:186\u001b[0m, in \u001b[0;36mpage_get_textpage\u001b[0;34m(_self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_get_textpage\u001b[39m(_self, clip, flags, matrix):\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tagged_data = []\n",
    "i = 1\n",
    "for url in df_raw_filtered['pdf-url']:\n",
    "    pdf_text = extract_text_from_pdf(url)\n",
    "    preprocessed_text = preprocess_text(pdf_text)\n",
    "    tagged_data.append(TaggedDocument(words=preprocessed_text, tags=[url]))\n",
    "    # print(preprocessed_text)\n",
    "    collection.add(\n",
    "                documents=pdf_text,\n",
    "                metadatas={\"url\": url},\n",
    "                ids=f\"doc{i}\",\n",
    "            )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b826c-cf79-42af-85a4-7947f1843a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"use cases, applications, application areas\"],\n",
    "    n_results=len(pdf_urls),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc6522-2bf7-43d1-927a-05cf7cfa8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    ")\n",
    "#\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=READER_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bac522-d634-4879-b06f-d44d9fd76108",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "                    Using the information contained in the context,\n",
    "                    give a comprehensive answer to the question.\n",
    "                    Respond only to the question asked, response should be concise and relevant to the question.\n",
    "                    Provide response in bullet points with an appropriate title.\n",
    "                    If the answer cannot be deduced from the context, do not give an answer.\n",
    "                \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c00c0-ce29-408e-a244-6404c86d573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What are the top use cases or application areas of retrieval augmented generation (RAG)? Emphasize on RAG applications with vector databases as well.\"\n",
    "k=len(pdf_urls)\n",
    "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
    "print(\"\\n==================================Top k documents==================================\")\n",
    "topk_retrieved_filename =  results['metadatas'][0][:k]\n",
    "topk_retrieved_file_id =  results['ids'][0][:k]\n",
    "topk_retrieved_file =  results['documents'][0][:k]\n",
    "print(f\"filename: {topk_retrieved_filename}\\nfile_id: {topk_retrieved_file_id}\")\n",
    "print(\"\\n==================================Top document==================================\")\n",
    "retrieved_filename =  results['metadatas'][0][0]\n",
    "retrieved_file_id =  results['ids'][0][0]\n",
    "retrieved_file =  results['documents'][0][0]\n",
    "# print(f\"filename: {retrieved_filename['filename']}\\nfile_id: {retrieved_file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca9cc8-81d8-44f0-9ed3-0552d1431c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_references(text):\n",
    "    words = text.split()\n",
    "    try:\n",
    "        references_index = words.index('References')\n",
    "        words_before_references = words[:references_index]\n",
    "        cleaned_text = ' '.join(words_before_references)\n",
    "    except ValueError:\n",
    "        return text\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd35a7c-b9d2-490f-9874-ec02f2fcd26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs_text = topk_retrieved_file[:100]\n",
    "for i in range(len(retrieved_docs_text)):\n",
    "    remove_references(retrieved_docs_text[i])\n",
    "context = \"\\nExtracted documents:\\n\"\n",
    "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
    "\n",
    "final_prompt = RAG_PROMPT_TEMPLATE.format(question=user_query, context=context)\n",
    "\n",
    "# print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c8f68-6160-4c08-9666-b01de959b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "answer = llm(final_prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa2e278-8881-4f33-862c-9a876a0f850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "# model.build_vocab(tagged_data)\n",
    "# model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46b1de-863b-4aee-9227-ed7032d55ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_vectors = {}\n",
    "# for url in pdf_urls:\n",
    "#     pdf_text = extract_text_from_pdf(url)\n",
    "#     preprocessed_text = preprocess_text(pdf_text)\n",
    "#     vector_representation = model.infer_vector(preprocessed_text)\n",
    "#     document_vectors[url] = vector_representation\n",
    "#     print(\"Added: \", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bb9d8-844b-45bf-ad81-92c13a54fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dim = len(next(iter(document_vectors.values())))\n",
    "# print(vector_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15927e6a-6795-41bd-acb5-ec5e76398b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = faiss.IndexFlatL2(vector_dim)\n",
    "# vectors_np = np.array(list(document_vectors.values())).astype('float32')\n",
    "# query_text = \"use cases, applications, application areas\"\n",
    "# query_vector = model.infer_vector(query_text.lower().split(\" \"))\n",
    "# query_vector_np = np.array([query_vector]).astype('float32')\n",
    "# k = len(pdf_urls)\n",
    "\n",
    "# index.reset()\n",
    "# index.add(vectors_np)\n",
    "# start_time = time.time()\n",
    "# distances, indices = index.search(query_vector_np, k=k)\n",
    "# end_time = time.time()\n",
    "# retrieval_time = (end_time - start_time) * 1e6\n",
    "# print(\"Retrieval time:\", retrieval_time, \"microseconds\")\n",
    "\n",
    "# results = pd.DataFrame({'distances': distances[0], 'ann': indices[0]})\n",
    "# print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c92751-3dc6-4b81-b6e3-de491a71aa99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss-env",
   "language": "python",
   "name": "faiss-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
