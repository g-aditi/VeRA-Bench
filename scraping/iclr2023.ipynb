{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc1376a-22c2-461a-a472-73a7f1ee60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openreview\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import fitz\n",
    "import io\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fa5ae8-c549-42fb-9d53-d005721b9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 3794/3798 [00:01<00:00, 2969.40it/s]\n"
     ]
    }
   ],
   "source": [
    "client = openreview.api.OpenReviewClient(baseurl='https://api.openreview.net')\n",
    "submissions = client.get_all_notes(content={'venueid':'ICLR.cc/2023/Conference'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa972eb-cf9f-4d56-92a7-241a774e427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(len(submissions)):\n",
    "    record = {\n",
    "        'URL': 'https://openreview.net/pdf?id=' + submissions[i].id,\n",
    "        'Title': submissions[i].content['title'],\n",
    "        'Keywords': submissions[i].content['keywords'],\n",
    "        'Abstract': submissions[i].content['abstract']\n",
    "    }\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e5433e-98d4-4112-b46f-f2b8dc3b523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records, columns=['URL', 'Title', 'Keywords', 'Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b67cf74-0dd1-4117-b854-3fff561157fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openreview.net/pdf?id=zzqBoIFOQ1</td>\n",
       "      <td>Guiding Safe Exploration with Weakest Precondi...</td>\n",
       "      <td>[reinforcement learning, safe learning, safe e...</td>\n",
       "      <td>In reinforcement learning for safety-critical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openreview.net/pdf?id=zzL_5WoI3I</td>\n",
       "      <td>An Adaptive Entropy-Regularization Framework f...</td>\n",
       "      <td>[Multi-Agent Reinforcement Learning, Entropy R...</td>\n",
       "      <td>In this paper, we propose an adaptive entropy-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openreview.net/pdf?id=zyfEWkV6it</td>\n",
       "      <td>AutoSparse: Towards Automated Sparse Training</td>\n",
       "      <td>[sparsity, sparse training, deep learning]</td>\n",
       "      <td>Sparse training is emerging as a promising ave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openreview.net/pdf?id=zyLVMgsZ0U_</td>\n",
       "      <td>Sampling is as easy as learning the score: the...</td>\n",
       "      <td>[diffusion models, score-based generative mode...</td>\n",
       "      <td>We provide theoretical convergence guarantees ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openreview.net/pdf?id=zufPou5foW</td>\n",
       "      <td>RoCourseNet: Distributionally Robust Training ...</td>\n",
       "      <td>[Counterfactual Explanation, Algorithmic Recou...</td>\n",
       "      <td>Counterfactual (CF) explanations for machine l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         URL  \\\n",
       "0   https://openreview.net/pdf?id=zzqBoIFOQ1   \n",
       "1   https://openreview.net/pdf?id=zzL_5WoI3I   \n",
       "2   https://openreview.net/pdf?id=zyfEWkV6it   \n",
       "3  https://openreview.net/pdf?id=zyLVMgsZ0U_   \n",
       "4   https://openreview.net/pdf?id=zufPou5foW   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Guiding Safe Exploration with Weakest Precondi...   \n",
       "1  An Adaptive Entropy-Regularization Framework f...   \n",
       "2      AutoSparse: Towards Automated Sparse Training   \n",
       "3  Sampling is as easy as learning the score: the...   \n",
       "4  RoCourseNet: Distributionally Robust Training ...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [reinforcement learning, safe learning, safe e...   \n",
       "1  [Multi-Agent Reinforcement Learning, Entropy R...   \n",
       "2         [sparsity, sparse training, deep learning]   \n",
       "3  [diffusion models, score-based generative mode...   \n",
       "4  [Counterfactual Explanation, Algorithmic Recou...   \n",
       "\n",
       "                                            Abstract  \n",
       "0  In reinforcement learning for safety-critical ...  \n",
       "1  In this paper, we propose an adaptive entropy-...  \n",
       "2  Sparse training is emerging as a promising ave...  \n",
       "3  We provide theoretical convergence guarantees ...  \n",
       "4  Counterfactual (CF) explanations for machine l...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2b1352-08f5-47d2-922b-81b178567675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_keywords(keyword_list):\n",
    "    return any(keyword.lower() in [kw.lower() for kw in keyword_list] for keyword in keywords_to_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7b34fd-df0f-4759-9ed8-cb477c78efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_to_filter = ['llm', 'rag', 'retrieval augmented generation', 'chatgpt', 'gpt', 'retrieval', 'vector databases', 'vector', 'nlp']\n",
    "filtered_df = df[df['Keywords'].apply(contains_keywords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b8a7d3-93c9-4411-9f4e-0b813b5bbb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02071a07-6980-44fc-9b08-5215f9968366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>https://openreview.net/pdf?id=yKbprarjc5B</td>\n",
       "      <td>Leveraging Large Language Models for Multiple ...</td>\n",
       "      <td>[NLP, language models, multiple choice questio...</td>\n",
       "      <td>While large language models (LLMs) like GPT-3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>https://openreview.net/pdf?id=wCFB37bzud4</td>\n",
       "      <td>Bidirectional Language Models Are Also Few-sho...</td>\n",
       "      <td>[prompting, prompt-based learning, mt5, t5, ma...</td>\n",
       "      <td>Large language models such as GPT-3 (Brown et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>https://openreview.net/pdf?id=vaxnu-Utr4l</td>\n",
       "      <td>WikiWhy: Answering and Explaining Cause-and-Ef...</td>\n",
       "      <td>[NLP, Question Answering, LLM, Dataset, Explan...</td>\n",
       "      <td>As large language models (LLMs) grow larger an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>https://openreview.net/pdf?id=tcbBPnfwxS</td>\n",
       "      <td>OPTQ: Accurate Quantization for Generative Pre...</td>\n",
       "      <td>[compression, quantization, generative pre-tra...</td>\n",
       "      <td>Generative Pre-trained Transformer models, kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>https://openreview.net/pdf?id=mumZwT6OrEV</td>\n",
       "      <td>ULF: UNSUPERVISED LABELING FUNCTION CORRECTION...</td>\n",
       "      <td>[nlp, weak supervision, text classification, s...</td>\n",
       "      <td>A way to overcome expensive and time-consuming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>https://openreview.net/pdf?id=hY6M0JHl3uL</td>\n",
       "      <td>Linear Connectivity Reveals Generalization Str...</td>\n",
       "      <td>[loss landscapes, OOD generalization, NLI, tex...</td>\n",
       "      <td>In the mode connectivity literature, it is wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>https://openreview.net/pdf?id=gEvzRWqFoCO</td>\n",
       "      <td>Contrastive Novelty Learning: Anticipating Out...</td>\n",
       "      <td>[selective prediction, open-set classification...</td>\n",
       "      <td>In many task settings, text classification mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>https://openreview.net/pdf?id=dz8i-yzXeVg</td>\n",
       "      <td>Elicitation Inference Optimization for Multi-P...</td>\n",
       "      <td>[alignment, large language models, LLMs, NLP, ...</td>\n",
       "      <td>In multi-principal-agent alignment scenarios s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>https://openreview.net/pdf?id=dGdoZds9qAs</td>\n",
       "      <td>Data Feedback Loops: Model-driven Amplificatio...</td>\n",
       "      <td>[feedback loops, bias amplification, deep lear...</td>\n",
       "      <td>Datasets scraped from the internet have been c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>https://openreview.net/pdf?id=am22IukDiKf</td>\n",
       "      <td>Learning by Distilling Context</td>\n",
       "      <td>[language models, NLP, prompting, distillation]</td>\n",
       "      <td>Language models significantly benefit from con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>https://openreview.net/pdf?id=_4F4CDK9Mo</td>\n",
       "      <td>RainProof: An Umbrella to Shield Text Generato...</td>\n",
       "      <td>[NLP, OOD detection, natural language generation]</td>\n",
       "      <td>As more and more conversational and translatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>https://openreview.net/pdf?id=ZqvoLWz05jT</td>\n",
       "      <td>Mask-tuning: Towards  Improving  Pre-trained L...</td>\n",
       "      <td>[NLP, Pre-trained langugae model, out-of-distr...</td>\n",
       "      <td>Pre-trained language models have the known gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>https://openreview.net/pdf?id=ZAzSf9pzCm</td>\n",
       "      <td>Efficient Sequence Packing without Cross-conta...</td>\n",
       "      <td>[deep learning, BERT, IPU, GPU, hardware-accel...</td>\n",
       "      <td>Effective training of today's large language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>https://openreview.net/pdf?id=WtW_s7EDWPe</td>\n",
       "      <td>Data-Efficient Finetuning Using Cross-Task Nea...</td>\n",
       "      <td>[multitasking, retrieval, few-shot, efficiency...</td>\n",
       "      <td>Language models trained on massive prompted mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>https://openreview.net/pdf?id=PUwbwZJz9dO</td>\n",
       "      <td>Measuring and Narrowing the Compositionality G...</td>\n",
       "      <td>[language modeling, prompting, question answer...</td>\n",
       "      <td>We investigate the ability of language models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>https://openreview.net/pdf?id=N_g8TT9Cy7f</td>\n",
       "      <td>Human-Guided Fair Classification for Natural L...</td>\n",
       "      <td>[Individual Fairness, Style Transfer, NLP, Cro...</td>\n",
       "      <td>Text classifiers have promising applications i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>https://openreview.net/pdf?id=NUU2tFxUjRa</td>\n",
       "      <td>Consistent Data Distribution Sampling for Larg...</td>\n",
       "      <td>[Retrieval, Neural Networks, Deep Learning, Re...</td>\n",
       "      <td>Retrieving candidate items with low latency an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>https://openreview.net/pdf?id=MtGmCCPJD-</td>\n",
       "      <td>Repository-Level Prompt Generation for Large L...</td>\n",
       "      <td>[prompt generation, codex, large language mode...</td>\n",
       "      <td>With the success of large language models (LLM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>https://openreview.net/pdf?id=MkbcAHIYgyS</td>\n",
       "      <td>Mass-Editing Memory in a Transformer</td>\n",
       "      <td>[language models, GPT, transformers, model edi...</td>\n",
       "      <td>Recent work has shown exciting promise in upda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>https://openreview.net/pdf?id=MFD2b2cwr5d</td>\n",
       "      <td>Learning from Others: Similarity-based Regula...</td>\n",
       "      <td>[NLP, robustness, spurious correlations, Datas...</td>\n",
       "      <td>Common methods for mitigating spurious correla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>https://openreview.net/pdf?id=LofRPZeXNNk</td>\n",
       "      <td>Preserving Semantics in Textual Adversarial At...</td>\n",
       "      <td>[NLP, Adversarial Attacks, Sentence Encoders, ...</td>\n",
       "      <td>Adversarial attacks in NLP challenge the way w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>https://openreview.net/pdf?id=LUql3ZOFwFD</td>\n",
       "      <td>Differentially Private Conditional Text Genera...</td>\n",
       "      <td>[differential privacy, conditional text genera...</td>\n",
       "      <td>Companies have faced increasing pressure in re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>https://openreview.net/pdf?id=KzkLAE49H9b</td>\n",
       "      <td>Training language models to summarize narrativ...</td>\n",
       "      <td>[language, nlp, neuroscience, fMRI, interpreta...</td>\n",
       "      <td>Building systems that achieve a deeper underst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>https://openreview.net/pdf?id=KRLUvxh8uaX</td>\n",
       "      <td>When and Why Vision-Language Models Behave lik...</td>\n",
       "      <td>[vision-language models, clip, contrastive lea...</td>\n",
       "      <td>Despite the success of large vision and langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>https://openreview.net/pdf?id=JZMR727O29</td>\n",
       "      <td>Backpropagation through Combinatorial Algorith...</td>\n",
       "      <td>[combinatorial optimization, deep learning, re...</td>\n",
       "      <td>Embedding discrete solvers as differentiable l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>https://openreview.net/pdf?id=HehQobsr0S</td>\n",
       "      <td>Text Summarization with Oracle Expectation</td>\n",
       "      <td>[Text Summarization, NLP]</td>\n",
       "      <td>Extractive summarization produces summaries by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>https://openreview.net/pdf?id=HdYxZ_OVZG</td>\n",
       "      <td>ThinkSum: Probabilistic reasoning over sets us...</td>\n",
       "      <td>[NLP, language models, prompting, zero-shot le...</td>\n",
       "      <td>Large language models (LLMs) have a substantia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>https://openreview.net/pdf?id=FkSp8VW8RjH</td>\n",
       "      <td>Language Modelling with Pixels</td>\n",
       "      <td>[representation learning, nlp, transformers, l...</td>\n",
       "      <td>Language models are defined over a finite set ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>https://openreview.net/pdf?id=DeG07_TcZvT</td>\n",
       "      <td>Emergent World Representations: Exploring a Se...</td>\n",
       "      <td>[world representation, GPT]</td>\n",
       "      <td>Language models show a surprising range of cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>https://openreview.net/pdf?id=CTX5JcDaUX9</td>\n",
       "      <td>Prefer to Classify: Improving Text Classifier ...</td>\n",
       "      <td>[NLP, text classification, annotation, disagre...</td>\n",
       "      <td>The development of largely human-annotated ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>https://openreview.net/pdf?id=CPg5IRu9PL</td>\n",
       "      <td>Efficient Large-scale Transformer Training via...</td>\n",
       "      <td>[Efficient Training, Large-scale Transformers,...</td>\n",
       "      <td>Large-scale transformer models have become the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>https://openreview.net/pdf?id=8yVy6LdhER4</td>\n",
       "      <td>Approximating How Single Head Attention Learns</td>\n",
       "      <td>[NLP, training dynamics, attention]</td>\n",
       "      <td>Why do models often attend to salient words, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>https://openreview.net/pdf?id=8tYRqb05pVn</td>\n",
       "      <td>Linearly Mapping from Image to Text Space</td>\n",
       "      <td>[representation learning, deep learning, groun...</td>\n",
       "      <td>The extent to which text-only language models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>https://openreview.net/pdf?id=7UudBVsIrr</td>\n",
       "      <td>MolJET: Multimodal Joint Embedding Transformer...</td>\n",
       "      <td>[Transformers, Multimodal, Molecules, Generati...</td>\n",
       "      <td>Multi-property constrained optimization of mol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>https://openreview.net/pdf?id=4bCsX2K0KuR</td>\n",
       "      <td>FiD-Light: Efficient and Effective Retrieval-A...</td>\n",
       "      <td>[retrieval augmented generation, KILT, Fusion-...</td>\n",
       "      <td>Retrieval-augmented generation models offer ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>https://openreview.net/pdf?id=4Fi-5Jiyy5w</td>\n",
       "      <td>Applying Second Order Optimization to Deep Tra...</td>\n",
       "      <td>[Pre-trained Models, NLP, Model Adaptation]</td>\n",
       "      <td>Despite the theoretical superiority in converg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>https://openreview.net/pdf?id=3TduOwfFNoy</td>\n",
       "      <td>Contextualized Generative Retrieval</td>\n",
       "      <td>[NLP, Information Retrieval]</td>\n",
       "      <td>The text retrieval task is mainly performed in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>https://openreview.net/pdf?id=-aEuKX6zQKmr</td>\n",
       "      <td>EmbedDistill: A geometric knowledge distillati...</td>\n",
       "      <td>[Knowledge distillation, dual encoder, cross e...</td>\n",
       "      <td>Large neural models (such as Transformers) ach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             URL  \\\n",
       "102    https://openreview.net/pdf?id=yKbprarjc5B   \n",
       "217    https://openreview.net/pdf?id=wCFB37bzud4   \n",
       "246    https://openreview.net/pdf?id=vaxnu-Utr4l   \n",
       "354     https://openreview.net/pdf?id=tcbBPnfwxS   \n",
       "748    https://openreview.net/pdf?id=mumZwT6OrEV   \n",
       "1079   https://openreview.net/pdf?id=hY6M0JHl3uL   \n",
       "1166   https://openreview.net/pdf?id=gEvzRWqFoCO   \n",
       "1289   https://openreview.net/pdf?id=dz8i-yzXeVg   \n",
       "1337   https://openreview.net/pdf?id=dGdoZds9qAs   \n",
       "1499   https://openreview.net/pdf?id=am22IukDiKf   \n",
       "1595    https://openreview.net/pdf?id=_4F4CDK9Mo   \n",
       "1614   https://openreview.net/pdf?id=ZqvoLWz05jT   \n",
       "1655    https://openreview.net/pdf?id=ZAzSf9pzCm   \n",
       "1780   https://openreview.net/pdf?id=WtW_s7EDWPe   \n",
       "2240   https://openreview.net/pdf?id=PUwbwZJz9dO   \n",
       "2359   https://openreview.net/pdf?id=N_g8TT9Cy7f   \n",
       "2366   https://openreview.net/pdf?id=NUU2tFxUjRa   \n",
       "2416    https://openreview.net/pdf?id=MtGmCCPJD-   \n",
       "2425   https://openreview.net/pdf?id=MkbcAHIYgyS   \n",
       "2455   https://openreview.net/pdf?id=MFD2b2cwr5d   \n",
       "2468   https://openreview.net/pdf?id=LofRPZeXNNk   \n",
       "2488   https://openreview.net/pdf?id=LUql3ZOFwFD   \n",
       "2517   https://openreview.net/pdf?id=KzkLAE49H9b   \n",
       "2550   https://openreview.net/pdf?id=KRLUvxh8uaX   \n",
       "2604    https://openreview.net/pdf?id=JZMR727O29   \n",
       "2706    https://openreview.net/pdf?id=HehQobsr0S   \n",
       "2708    https://openreview.net/pdf?id=HdYxZ_OVZG   \n",
       "2806   https://openreview.net/pdf?id=FkSp8VW8RjH   \n",
       "2909   https://openreview.net/pdf?id=DeG07_TcZvT   \n",
       "2961   https://openreview.net/pdf?id=CTX5JcDaUX9   \n",
       "2966    https://openreview.net/pdf?id=CPg5IRu9PL   \n",
       "3159   https://openreview.net/pdf?id=8yVy6LdhER4   \n",
       "3168   https://openreview.net/pdf?id=8tYRqb05pVn   \n",
       "3255    https://openreview.net/pdf?id=7UudBVsIrr   \n",
       "3441   https://openreview.net/pdf?id=4bCsX2K0KuR   \n",
       "3462   https://openreview.net/pdf?id=4Fi-5Jiyy5w   \n",
       "3537   https://openreview.net/pdf?id=3TduOwfFNoy   \n",
       "3764  https://openreview.net/pdf?id=-aEuKX6zQKmr   \n",
       "\n",
       "                                                  Title  \\\n",
       "102   Leveraging Large Language Models for Multiple ...   \n",
       "217   Bidirectional Language Models Are Also Few-sho...   \n",
       "246   WikiWhy: Answering and Explaining Cause-and-Ef...   \n",
       "354   OPTQ: Accurate Quantization for Generative Pre...   \n",
       "748   ULF: UNSUPERVISED LABELING FUNCTION CORRECTION...   \n",
       "1079  Linear Connectivity Reveals Generalization Str...   \n",
       "1166  Contrastive Novelty Learning: Anticipating Out...   \n",
       "1289  Elicitation Inference Optimization for Multi-P...   \n",
       "1337  Data Feedback Loops: Model-driven Amplificatio...   \n",
       "1499                     Learning by Distilling Context   \n",
       "1595  RainProof: An Umbrella to Shield Text Generato...   \n",
       "1614  Mask-tuning: Towards  Improving  Pre-trained L...   \n",
       "1655  Efficient Sequence Packing without Cross-conta...   \n",
       "1780  Data-Efficient Finetuning Using Cross-Task Nea...   \n",
       "2240  Measuring and Narrowing the Compositionality G...   \n",
       "2359  Human-Guided Fair Classification for Natural L...   \n",
       "2366  Consistent Data Distribution Sampling for Larg...   \n",
       "2416  Repository-Level Prompt Generation for Large L...   \n",
       "2425               Mass-Editing Memory in a Transformer   \n",
       "2455   Learning from Others: Similarity-based Regula...   \n",
       "2468  Preserving Semantics in Textual Adversarial At...   \n",
       "2488  Differentially Private Conditional Text Genera...   \n",
       "2517  Training language models to summarize narrativ...   \n",
       "2550  When and Why Vision-Language Models Behave lik...   \n",
       "2604  Backpropagation through Combinatorial Algorith...   \n",
       "2706         Text Summarization with Oracle Expectation   \n",
       "2708  ThinkSum: Probabilistic reasoning over sets us...   \n",
       "2806                     Language Modelling with Pixels   \n",
       "2909  Emergent World Representations: Exploring a Se...   \n",
       "2961  Prefer to Classify: Improving Text Classifier ...   \n",
       "2966  Efficient Large-scale Transformer Training via...   \n",
       "3159     Approximating How Single Head Attention Learns   \n",
       "3168          Linearly Mapping from Image to Text Space   \n",
       "3255  MolJET: Multimodal Joint Embedding Transformer...   \n",
       "3441  FiD-Light: Efficient and Effective Retrieval-A...   \n",
       "3462  Applying Second Order Optimization to Deep Tra...   \n",
       "3537                Contextualized Generative Retrieval   \n",
       "3764  EmbedDistill: A geometric knowledge distillati...   \n",
       "\n",
       "                                               Keywords  \\\n",
       "102   [NLP, language models, multiple choice questio...   \n",
       "217   [prompting, prompt-based learning, mt5, t5, ma...   \n",
       "246   [NLP, Question Answering, LLM, Dataset, Explan...   \n",
       "354   [compression, quantization, generative pre-tra...   \n",
       "748   [nlp, weak supervision, text classification, s...   \n",
       "1079  [loss landscapes, OOD generalization, NLI, tex...   \n",
       "1166  [selective prediction, open-set classification...   \n",
       "1289  [alignment, large language models, LLMs, NLP, ...   \n",
       "1337  [feedback loops, bias amplification, deep lear...   \n",
       "1499    [language models, NLP, prompting, distillation]   \n",
       "1595  [NLP, OOD detection, natural language generation]   \n",
       "1614  [NLP, Pre-trained langugae model, out-of-distr...   \n",
       "1655  [deep learning, BERT, IPU, GPU, hardware-accel...   \n",
       "1780  [multitasking, retrieval, few-shot, efficiency...   \n",
       "2240  [language modeling, prompting, question answer...   \n",
       "2359  [Individual Fairness, Style Transfer, NLP, Cro...   \n",
       "2366  [Retrieval, Neural Networks, Deep Learning, Re...   \n",
       "2416  [prompt generation, codex, large language mode...   \n",
       "2425  [language models, GPT, transformers, model edi...   \n",
       "2455  [NLP, robustness, spurious correlations, Datas...   \n",
       "2468  [NLP, Adversarial Attacks, Sentence Encoders, ...   \n",
       "2488  [differential privacy, conditional text genera...   \n",
       "2517  [language, nlp, neuroscience, fMRI, interpreta...   \n",
       "2550  [vision-language models, clip, contrastive lea...   \n",
       "2604  [combinatorial optimization, deep learning, re...   \n",
       "2706                          [Text Summarization, NLP]   \n",
       "2708  [NLP, language models, prompting, zero-shot le...   \n",
       "2806  [representation learning, nlp, transformers, l...   \n",
       "2909                        [world representation, GPT]   \n",
       "2961  [NLP, text classification, annotation, disagre...   \n",
       "2966  [Efficient Training, Large-scale Transformers,...   \n",
       "3159                [NLP, training dynamics, attention]   \n",
       "3168  [representation learning, deep learning, groun...   \n",
       "3255  [Transformers, Multimodal, Molecules, Generati...   \n",
       "3441  [retrieval augmented generation, KILT, Fusion-...   \n",
       "3462        [Pre-trained Models, NLP, Model Adaptation]   \n",
       "3537                       [NLP, Information Retrieval]   \n",
       "3764  [Knowledge distillation, dual encoder, cross e...   \n",
       "\n",
       "                                               Abstract  \n",
       "102   While large language models (LLMs) like GPT-3 ...  \n",
       "217   Large language models such as GPT-3 (Brown et ...  \n",
       "246   As large language models (LLMs) grow larger an...  \n",
       "354   Generative Pre-trained Transformer models, kno...  \n",
       "748   A way to overcome expensive and time-consuming...  \n",
       "1079  In the mode connectivity literature, it is wid...  \n",
       "1166  In many task settings, text classification mod...  \n",
       "1289  In multi-principal-agent alignment scenarios s...  \n",
       "1337  Datasets scraped from the internet have been c...  \n",
       "1499  Language models significantly benefit from con...  \n",
       "1595  As more and more conversational and translatio...  \n",
       "1614  Pre-trained language models have the known gen...  \n",
       "1655  Effective training of today's large language m...  \n",
       "1780  Language models trained on massive prompted mu...  \n",
       "2240  We investigate the ability of language models ...  \n",
       "2359  Text classifiers have promising applications i...  \n",
       "2366  Retrieving candidate items with low latency an...  \n",
       "2416  With the success of large language models (LLM...  \n",
       "2425  Recent work has shown exciting promise in upda...  \n",
       "2455  Common methods for mitigating spurious correla...  \n",
       "2468  Adversarial attacks in NLP challenge the way w...  \n",
       "2488  Companies have faced increasing pressure in re...  \n",
       "2517  Building systems that achieve a deeper underst...  \n",
       "2550  Despite the success of large vision and langua...  \n",
       "2604  Embedding discrete solvers as differentiable l...  \n",
       "2706  Extractive summarization produces summaries by...  \n",
       "2708  Large language models (LLMs) have a substantia...  \n",
       "2806  Language models are defined over a finite set ...  \n",
       "2909  Language models show a surprising range of cap...  \n",
       "2961  The development of largely human-annotated ben...  \n",
       "2966  Large-scale transformer models have become the...  \n",
       "3159  Why do models often attend to salient words, a...  \n",
       "3168  The extent to which text-only language models ...  \n",
       "3255  Multi-property constrained optimization of mol...  \n",
       "3441  Retrieval-augmented generation models offer ma...  \n",
       "3462  Despite the theoretical superiority in converg...  \n",
       "3537  The text retrieval task is mainly performed in...  \n",
       "3764  Large neural models (such as Transformers) ach...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005cda95-1dca-45d6-ac93-ccf60ef4b6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29453f12314c4a9da0e2c9a44dcbfa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=READER_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da28c21-1f06-4d7a-ab38-bd440dfd75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperAnalysisPipeline:\n",
    "    def extract_text_from_pdf(self, paper_url):\n",
    "        response = requests.get(paper_url)\n",
    "        pdf_content = response.content\n",
    "        text = \"\"\n",
    "        with fitz.open(stream=io.BytesIO(pdf_content)) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "\n",
    "    def extract_introduction(self, text):\n",
    "        text = text.lower()\n",
    "        introduction_start = text.find(\"introduction\")\n",
    "        lit_review_start = text.find(\"related work\")\n",
    "        if lit_review_start == -1:\n",
    "            lit_review_start = text.find(\"related works\")\n",
    "            if lit_review_start == -1:\n",
    "                lit_review_start = text.find(\"background\")\n",
    "                if lit_review_start == -1:\n",
    "                    lit_review_start = text.find(\"previous work\")\n",
    "        introduction_text = text[introduction_start:lit_review_start].strip()\n",
    "        introduction_paragraphs = introduction_text.split('\\n\\n')[:3]\n",
    "        return '\\n\\n'.join(introduction_paragraphs)\n",
    "\n",
    "    def extract_conclusion(self, text):\n",
    "        text = text.lower()\n",
    "        conclusion_start = text.find(\"conclusion\")\n",
    "        future_work_start = text.find(\"future work\")\n",
    "        if future_work_start == -1:\n",
    "            future_work_start = text.find(\"references\")\n",
    "        conclusion_text = text[conclusion_start:future_work_start].strip()\n",
    "        conclusion_paragraphs = conclusion_text.split('\\n\\n')[:1]\n",
    "        return '\\n\\n'.join(conclusion_paragraphs)\n",
    "\n",
    "    def stitch_relevant_sections(self, title, abstract, conclusion):\n",
    "        context = ''\n",
    "        context += title + abstract + conclusion\n",
    "        return context\n",
    "\n",
    "    def ask_llm_with_context(self, context):\n",
    "        prompt = f\"\"\"\n",
    "        Using the information contained in the context,\n",
    "        give a comprehensive answer to the question.\n",
    "        If the answer to the first question is affirmative, answer the questions that follow.\n",
    "        Context:\n",
    "        {context}\n",
    "        ---\n",
    "        Now here is the question you need to answer.\n",
    "\n",
    "        Question 1: Does this paper use retrieval-augmented generation (RAG)?\n",
    "        Question 2: If the answer to Question 1 is yes, how and where is the LLM used to solve real-world problems?\n",
    "        Question 3: If the answer to Question 1 is yes, does it talk about applying RAG in traditional natural language \n",
    "                    processing (NLP) applications? Which NLP applications does it mention?\n",
    "        \"\"\"\n",
    "        answer = llm(prompt)\n",
    "        return answer\n",
    "        \n",
    "    def print_text(self, text):\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde0195-d864-4b5e-ba58-ff0da7338bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PAPER 1: Leveraging Large Language Models for Multiple Choice Question Answering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aganap12/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Answer:\n",
      "        No, this paper does not use retrieval-augmented generation (RAG). The focus of this paper is on leveraging large language models (LLMs) for multiple choice question answering (MCQA), specifically exploring the effectiveness of presenting questions and answer options to LLMs jointly instead of as separate inputs. The authors argue that this \"natural\" approach allows the LLM to explicitly compare answer options, reducing computational costs and mitigating the effects of tokenization scheme and answer option representations on answer selection. They also introduce the concept of multiple choice symbol binding (MCSB) ability, which refers to an LLM's ability to associate answer options with symbols that represent them. The authors demonstrate that a model with high MCSB ability performs much better with the natural approach than with the traditional approach across 20 diverse datasets and largely closes the gap with the state of the art (SOTA), suggesting that the MCQA ability of LLMs has been previously underestimated.\n",
      "        The paper does not discuss applying LLMs in traditional natural language processing (NLP) applications using RAG.\n",
      "\n",
      "\n",
      "\n",
      "PAPER 2: Bidirectional Language Models Are Also Few-shot Learners\n",
      "\n",
      "        Based on the text material above, generate the response to the following quesion or instruction: Can you provide a summary of the paper \"Bidirectional Language Models Are Also Few-shot Learners\" by Xue et al. (2021)?\n",
      "\n",
      "\n",
      "PAPER 3: WikiWhy: Answering and Explaining Cause-and-Effect Questions\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "PAPER 4: OPTQ: Accurate Quantization for Generative Pre-trained Transformers\n",
      "\n",
      "        Answer: No, the paper \"Accurate Quantization for Generative Pre-trained Transformers\" by Zhang et al. Does not use retrieval-augmented generation (RAG). Therefore, Questions 2 and 3 do not apply in this case.\n",
      "\n",
      "\n",
      "PAPER 5: ULF: UNSUPERVISED LABELING FUNCTION CORRECTION USING CROSS-VALIDATION FOR WEAK SUPERVISION\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_df)):\n",
    "    paper_url = filtered_df.iloc[i].URL\n",
    "    paper_title = filtered_df.iloc[i].Title\n",
    "    abstract = filtered_df.iloc[i].Abstract\n",
    "    print(f\"\\n\\nPAPER {i+1}: {paper_title}\")\n",
    "    analysis_pipeline = PaperAnalysisPipeline()\n",
    "    text = analysis_pipeline.extract_text_from_pdf(paper_url)\n",
    "    # introduction = analysis_pipeline.extract_introduction(text)\n",
    "    conclusion = analysis_pipeline.extract_conclusion(text)\n",
    "    context = analysis_pipeline.stitch_relevant_sections(paper_title, abstract, conclusion)\n",
    "    llm_response = analysis_pipeline.ask_llm_with_context(context)\n",
    "    analysis_pipeline.print_text(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ec110-d74a-4a99-bc63-936e3bf92832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
