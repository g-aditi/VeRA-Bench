{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa80093-3d2b-40c5-9f66-4e411af9631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aganap12/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import document_loaders as dl\n",
    "from langchain import embeddings\n",
    "from langchain import text_splitter as ts\n",
    "from langchain import vectorstores as vs\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd5cc9f-e0eb-4e38-a505-837ad50dd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from replicate.client import Client\n",
    "\n",
    "replicate = Client(api_token=\"r8_IbZu0U3qUJ5ZC0TzzMm6xCJ6yU5UxVi16Ejo4\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./chromadb-client\")\n",
    "collection = client.get_or_create_collection(\"aws-blogs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6983b50-2f21-452a-9b74-e5b6f22d0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2024-04-17 19:06:41.268719392 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655288, index: 0, mask: {1, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.290222895 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655289, index: 1, mask: {2, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.310334302 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655290, index: 2, mask: {3, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.315109097 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655291, index: 3, mask: {4, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.334767179 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655292, index: 4, mask: {5, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.349936997 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655293, index: 5, mask: {6, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.364098323 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655294, index: 6, mask: {7, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.375102976 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655295, index: 7, mask: {8, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.389098911 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655296, index: 8, mask: {9, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.405236243 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655297, index: 9, mask: {10, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.414098676 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655298, index: 10, mask: {11, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.429296207 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655299, index: 11, mask: {12, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.439099734 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655300, index: 12, mask: {13, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.450101573 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655301, index: 13, mask: {14, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.464113627 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655302, index: 14, mask: {15, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.475102430 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655303, index: 15, mask: {16, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.485095817 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655304, index: 16, mask: {17, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.505103639 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655305, index: 17, mask: {18, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.517096465 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655306, index: 18, mask: {19, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.535425290 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655307, index: 19, mask: {20, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.550599367 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655308, index: 20, mask: {21, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.555132636 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655309, index: 21, mask: {22, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.566100750 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655310, index: 22, mask: {23, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.581272171 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655311, index: 23, mask: {24, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.594099291 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655312, index: 24, mask: {25, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.605104776 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655313, index: 25, mask: {26, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.620266088 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655314, index: 26, mask: {27, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.635426177 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655315, index: 27, mask: {28, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.640097848 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655316, index: 28, mask: {29, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.660211990 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655317, index: 29, mask: {30, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.690537840 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655319, index: 31, mask: {32, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.703097576 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655320, index: 32, mask: {33, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.720533177 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655321, index: 33, mask: {34, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.735699829 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655322, index: 34, mask: {35, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.750861602 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655323, index: 35, mask: {36, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.757093414 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655324, index: 36, mask: {37, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.776100108 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655325, index: 37, mask: {38, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.791273393 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655326, index: 38, mask: {39, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.806101016 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655327, index: 39, mask: {40, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.825660692 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655328, index: 40, mask: {41, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.840823647 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655329, index: 41, mask: {42, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.855991802 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655330, index: 42, mask: {43, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.871159857 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655331, index: 43, mask: {44, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.878094775 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655332, index: 44, mask: {45, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.896427077 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655333, index: 45, mask: {46, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2024-04-17 19:06:41.910103750 [E:onnxruntime:Default, env.cc:254 ThreadMain] pthread_setaffinity_np failed for thread: 3655334, index: 46, mask: {47, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "Add of existing embedding ID: doc1\n",
      "Add of existing embedding ID: doc2\n",
      "Add of existing embedding ID: doc3\n",
      "Add of existing embedding ID: doc4\n",
      "Add of existing embedding ID: doc5\n",
      "Add of existing embedding ID: doc6\n",
      "Add of existing embedding ID: doc7\n",
      "Add of existing embedding ID: doc8\n",
      "Add of existing embedding ID: doc9\n",
      "Add of existing embedding ID: doc10\n",
      "Add of existing embedding ID: doc11\n",
      "Add of existing embedding ID: doc12\n",
      "Add of existing embedding ID: doc13\n",
      "Add of existing embedding ID: doc14\n",
      "Add of existing embedding ID: doc15\n",
      "Add of existing embedding ID: doc16\n",
      "Add of existing embedding ID: doc17\n",
      "Add of existing embedding ID: doc18\n",
      "Add of existing embedding ID: doc19\n",
      "Add of existing embedding ID: doc20\n",
      "Add of existing embedding ID: doc21\n",
      "Add of existing embedding ID: doc22\n",
      "Add of existing embedding ID: doc23\n",
      "Add of existing embedding ID: doc24\n",
      "Add of existing embedding ID: doc25\n",
      "Add of existing embedding ID: doc26\n",
      "Add of existing embedding ID: doc27\n",
      "Add of existing embedding ID: doc28\n",
      "Add of existing embedding ID: doc29\n",
      "Add of existing embedding ID: doc30\n",
      "Add of existing embedding ID: doc31\n",
      "Add of existing embedding ID: doc32\n",
      "Add of existing embedding ID: doc33\n",
      "Add of existing embedding ID: doc34\n",
      "Insert of existing embedding ID: doc1\n",
      "Add of existing embedding ID: doc1\n",
      "Insert of existing embedding ID: doc2\n",
      "Add of existing embedding ID: doc2\n",
      "Insert of existing embedding ID: doc3\n",
      "Add of existing embedding ID: doc3\n",
      "Insert of existing embedding ID: doc4\n",
      "Add of existing embedding ID: doc4\n",
      "Insert of existing embedding ID: doc5\n",
      "Add of existing embedding ID: doc5\n",
      "Insert of existing embedding ID: doc6\n",
      "Add of existing embedding ID: doc6\n",
      "Insert of existing embedding ID: doc7\n",
      "Add of existing embedding ID: doc7\n",
      "Insert of existing embedding ID: doc8\n",
      "Add of existing embedding ID: doc8\n",
      "Insert of existing embedding ID: doc9\n",
      "Add of existing embedding ID: doc9\n",
      "Insert of existing embedding ID: doc10\n",
      "Add of existing embedding ID: doc10\n",
      "Insert of existing embedding ID: doc11\n",
      "Add of existing embedding ID: doc11\n",
      "Insert of existing embedding ID: doc12\n",
      "Add of existing embedding ID: doc12\n",
      "Insert of existing embedding ID: doc13\n",
      "Add of existing embedding ID: doc13\n",
      "Insert of existing embedding ID: doc14\n",
      "Add of existing embedding ID: doc14\n",
      "Insert of existing embedding ID: doc15\n",
      "Add of existing embedding ID: doc15\n",
      "Insert of existing embedding ID: doc16\n",
      "Add of existing embedding ID: doc16\n",
      "Insert of existing embedding ID: doc17\n",
      "Add of existing embedding ID: doc17\n",
      "Insert of existing embedding ID: doc18\n",
      "Add of existing embedding ID: doc18\n",
      "Insert of existing embedding ID: doc19\n",
      "Add of existing embedding ID: doc19\n",
      "Insert of existing embedding ID: doc20\n",
      "Add of existing embedding ID: doc20\n",
      "Insert of existing embedding ID: doc21\n",
      "Add of existing embedding ID: doc21\n",
      "Insert of existing embedding ID: doc22\n",
      "Add of existing embedding ID: doc22\n",
      "Insert of existing embedding ID: doc23\n",
      "Add of existing embedding ID: doc23\n",
      "Insert of existing embedding ID: doc24\n",
      "Add of existing embedding ID: doc24\n",
      "Insert of existing embedding ID: doc25\n",
      "Add of existing embedding ID: doc25\n",
      "Insert of existing embedding ID: doc26\n",
      "Add of existing embedding ID: doc26\n",
      "Insert of existing embedding ID: doc27\n",
      "Add of existing embedding ID: doc27\n",
      "Insert of existing embedding ID: doc28\n",
      "Add of existing embedding ID: doc28\n",
      "Insert of existing embedding ID: doc29\n",
      "Add of existing embedding ID: doc29\n",
      "Insert of existing embedding ID: doc30\n",
      "Add of existing embedding ID: doc30\n",
      "Insert of existing embedding ID: doc31\n",
      "Add of existing embedding ID: doc31\n",
      "Insert of existing embedding ID: doc32\n",
      "Add of existing embedding ID: doc32\n",
      "Insert of existing embedding ID: doc33\n",
      "Add of existing embedding ID: doc33\n",
      "Insert of existing embedding ID: doc34\n",
      "Add of existing embedding ID: doc34\n",
      "Insert of existing embedding ID: doc35\n",
      "Add of existing embedding ID: doc35\n",
      "Insert of existing embedding ID: doc36\n",
      "Add of existing embedding ID: doc36\n",
      "Insert of existing embedding ID: doc37\n",
      "Add of existing embedding ID: doc37\n",
      "Insert of existing embedding ID: doc38\n",
      "Add of existing embedding ID: doc38\n",
      "Insert of existing embedding ID: doc39\n",
      "Add of existing embedding ID: doc39\n",
      "Insert of existing embedding ID: doc40\n",
      "Add of existing embedding ID: doc40\n",
      "Insert of existing embedding ID: doc41\n",
      "Add of existing embedding ID: doc41\n",
      "Insert of existing embedding ID: doc42\n",
      "Add of existing embedding ID: doc42\n",
      "Insert of existing embedding ID: doc43\n",
      "Add of existing embedding ID: doc43\n",
      "Insert of existing embedding ID: doc44\n",
      "Add of existing embedding ID: doc44\n",
      "Insert of existing embedding ID: doc45\n",
      "Add of existing embedding ID: doc45\n",
      "Insert of existing embedding ID: doc46\n",
      "Add of existing embedding ID: doc46\n",
      "Insert of existing embedding ID: doc47\n",
      "Add of existing embedding ID: doc47\n",
      "Insert of existing embedding ID: doc48\n",
      "Add of existing embedding ID: doc48\n",
      "Insert of existing embedding ID: doc49\n",
      "Add of existing embedding ID: doc49\n",
      "Insert of existing embedding ID: doc50\n",
      "Add of existing embedding ID: doc50\n",
      "Insert of existing embedding ID: doc51\n",
      "Add of existing embedding ID: doc51\n",
      "Insert of existing embedding ID: doc52\n",
      "Add of existing embedding ID: doc52\n",
      "Insert of existing embedding ID: doc53\n",
      "Add of existing embedding ID: doc53\n",
      "Insert of existing embedding ID: doc54\n",
      "Add of existing embedding ID: doc54\n",
      "Insert of existing embedding ID: doc55\n",
      "Add of existing embedding ID: doc55\n",
      "Insert of existing embedding ID: doc56\n",
      "Add of existing embedding ID: doc56\n",
      "Insert of existing embedding ID: doc57\n",
      "Add of existing embedding ID: doc57\n",
      "Insert of existing embedding ID: doc58\n",
      "Add of existing embedding ID: doc58\n",
      "Insert of existing embedding ID: doc59\n",
      "Add of existing embedding ID: doc59\n",
      "Insert of existing embedding ID: doc60\n",
      "Add of existing embedding ID: doc60\n",
      "Insert of existing embedding ID: doc61\n",
      "Add of existing embedding ID: doc61\n",
      "Insert of existing embedding ID: doc62\n",
      "Add of existing embedding ID: doc62\n",
      "Insert of existing embedding ID: doc63\n",
      "Add of existing embedding ID: doc63\n",
      "Insert of existing embedding ID: doc64\n",
      "Add of existing embedding ID: doc64\n",
      "Insert of existing embedding ID: doc65\n",
      "Add of existing embedding ID: doc65\n",
      "Insert of existing embedding ID: doc66\n",
      "Add of existing embedding ID: doc66\n",
      "Insert of existing embedding ID: doc67\n",
      "Add of existing embedding ID: doc67\n",
      "Insert of existing embedding ID: doc68\n",
      "Add of existing embedding ID: doc68\n",
      "Insert of existing embedding ID: doc69\n",
      "Add of existing embedding ID: doc69\n",
      "Insert of existing embedding ID: doc70\n",
      "Add of existing embedding ID: doc70\n",
      "Insert of existing embedding ID: doc71\n",
      "Add of existing embedding ID: doc71\n",
      "Insert of existing embedding ID: doc72\n",
      "Add of existing embedding ID: doc72\n",
      "Insert of existing embedding ID: doc73\n",
      "Add of existing embedding ID: doc73\n",
      "Insert of existing embedding ID: doc74\n",
      "Add of existing embedding ID: doc74\n",
      "Insert of existing embedding ID: doc75\n",
      "Add of existing embedding ID: doc75\n",
      "Insert of existing embedding ID: doc76\n",
      "Add of existing embedding ID: doc76\n",
      "Insert of existing embedding ID: doc77\n",
      "Add of existing embedding ID: doc77\n",
      "Insert of existing embedding ID: doc78\n",
      "Add of existing embedding ID: doc78\n",
      "Insert of existing embedding ID: doc79\n",
      "Add of existing embedding ID: doc79\n",
      "Insert of existing embedding ID: doc80\n",
      "Add of existing embedding ID: doc80\n",
      "Insert of existing embedding ID: doc81\n",
      "Add of existing embedding ID: doc81\n",
      "Insert of existing embedding ID: doc82\n",
      "Add of existing embedding ID: doc82\n",
      "Insert of existing embedding ID: doc83\n",
      "Add of existing embedding ID: doc83\n",
      "Insert of existing embedding ID: doc84\n",
      "Add of existing embedding ID: doc84\n",
      "Insert of existing embedding ID: doc85\n",
      "Add of existing embedding ID: doc85\n",
      "Insert of existing embedding ID: doc86\n",
      "Add of existing embedding ID: doc86\n",
      "Insert of existing embedding ID: doc87\n",
      "Add of existing embedding ID: doc87\n",
      "Insert of existing embedding ID: doc88\n",
      "Add of existing embedding ID: doc88\n",
      "Insert of existing embedding ID: doc89\n",
      "Add of existing embedding ID: doc89\n",
      "Insert of existing embedding ID: doc90\n",
      "Add of existing embedding ID: doc90\n",
      "Insert of existing embedding ID: doc91\n",
      "Add of existing embedding ID: doc91\n",
      "Insert of existing embedding ID: doc92\n",
      "Add of existing embedding ID: doc92\n",
      "Insert of existing embedding ID: doc93\n",
      "Add of existing embedding ID: doc93\n",
      "Insert of existing embedding ID: doc94\n",
      "Add of existing embedding ID: doc94\n",
      "Insert of existing embedding ID: doc95\n",
      "Add of existing embedding ID: doc95\n",
      "Insert of existing embedding ID: doc96\n",
      "Add of existing embedding ID: doc96\n",
      "Insert of existing embedding ID: doc97\n",
      "Add of existing embedding ID: doc97\n",
      "Insert of existing embedding ID: doc98\n",
      "Add of existing embedding ID: doc98\n",
      "Insert of existing embedding ID: doc99\n",
      "Add of existing embedding ID: doc99\n",
      "Insert of existing embedding ID: doc100\n",
      "Add of existing embedding ID: doc100\n",
      "Insert of existing embedding ID: doc101\n",
      "Add of existing embedding ID: doc101\n",
      "Insert of existing embedding ID: doc102\n",
      "Add of existing embedding ID: doc102\n",
      "Insert of existing embedding ID: doc103\n",
      "Add of existing embedding ID: doc103\n",
      "Insert of existing embedding ID: doc104\n",
      "Add of existing embedding ID: doc104\n",
      "Insert of existing embedding ID: doc105\n",
      "Add of existing embedding ID: doc105\n",
      "Insert of existing embedding ID: doc106\n",
      "Add of existing embedding ID: doc106\n",
      "Insert of existing embedding ID: doc107\n",
      "Add of existing embedding ID: doc107\n",
      "Insert of existing embedding ID: doc108\n",
      "Add of existing embedding ID: doc108\n",
      "Insert of existing embedding ID: doc109\n",
      "Add of existing embedding ID: doc109\n",
      "Insert of existing embedding ID: doc110\n",
      "Add of existing embedding ID: doc110\n",
      "Insert of existing embedding ID: doc111\n",
      "Add of existing embedding ID: doc111\n",
      "Insert of existing embedding ID: doc112\n",
      "Add of existing embedding ID: doc112\n",
      "Insert of existing embedding ID: doc113\n",
      "Add of existing embedding ID: doc113\n",
      "Insert of existing embedding ID: doc114\n",
      "Add of existing embedding ID: doc114\n",
      "Insert of existing embedding ID: doc115\n",
      "Add of existing embedding ID: doc115\n",
      "Insert of existing embedding ID: doc116\n",
      "Add of existing embedding ID: doc116\n",
      "Insert of existing embedding ID: doc117\n",
      "Add of existing embedding ID: doc117\n",
      "Insert of existing embedding ID: doc118\n",
      "Add of existing embedding ID: doc118\n",
      "Insert of existing embedding ID: doc119\n",
      "Add of existing embedding ID: doc119\n",
      "Insert of existing embedding ID: doc120\n",
      "Add of existing embedding ID: doc120\n",
      "Insert of existing embedding ID: doc121\n",
      "Add of existing embedding ID: doc121\n",
      "Insert of existing embedding ID: doc122\n",
      "Add of existing embedding ID: doc122\n",
      "Insert of existing embedding ID: doc123\n",
      "Add of existing embedding ID: doc123\n",
      "Insert of existing embedding ID: doc124\n",
      "Add of existing embedding ID: doc124\n",
      "Insert of existing embedding ID: doc125\n",
      "Add of existing embedding ID: doc125\n",
      "Insert of existing embedding ID: doc126\n",
      "Add of existing embedding ID: doc126\n",
      "Insert of existing embedding ID: doc127\n",
      "Add of existing embedding ID: doc127\n",
      "Insert of existing embedding ID: doc128\n",
      "Add of existing embedding ID: doc128\n",
      "Insert of existing embedding ID: doc129\n",
      "Add of existing embedding ID: doc129\n",
      "Insert of existing embedding ID: doc130\n",
      "Add of existing embedding ID: doc130\n",
      "Insert of existing embedding ID: doc131\n",
      "Add of existing embedding ID: doc131\n",
      "Insert of existing embedding ID: doc132\n",
      "Add of existing embedding ID: doc132\n",
      "Insert of existing embedding ID: doc133\n",
      "Add of existing embedding ID: doc133\n",
      "Insert of existing embedding ID: doc134\n",
      "Add of existing embedding ID: doc134\n",
      "Insert of existing embedding ID: doc135\n",
      "Add of existing embedding ID: doc135\n",
      "Insert of existing embedding ID: doc136\n",
      "Add of existing embedding ID: doc136\n",
      "Insert of existing embedding ID: doc137\n",
      "Add of existing embedding ID: doc137\n",
      "Insert of existing embedding ID: doc138\n",
      "Add of existing embedding ID: doc138\n",
      "Insert of existing embedding ID: doc139\n",
      "Add of existing embedding ID: doc139\n",
      "Insert of existing embedding ID: doc140\n",
      "Add of existing embedding ID: doc140\n",
      "Insert of existing embedding ID: doc141\n",
      "Add of existing embedding ID: doc141\n",
      "Insert of existing embedding ID: doc142\n",
      "Add of existing embedding ID: doc142\n",
      "Insert of existing embedding ID: doc143\n",
      "Add of existing embedding ID: doc143\n",
      "Insert of existing embedding ID: doc144\n",
      "Add of existing embedding ID: doc144\n",
      "Insert of existing embedding ID: doc145\n",
      "Add of existing embedding ID: doc145\n",
      "Insert of existing embedding ID: doc146\n",
      "Add of existing embedding ID: doc146\n",
      "Insert of existing embedding ID: doc147\n",
      "Add of existing embedding ID: doc147\n",
      "Insert of existing embedding ID: doc148\n",
      "Add of existing embedding ID: doc148\n",
      "Insert of existing embedding ID: doc149\n",
      "Add of existing embedding ID: doc149\n",
      "Insert of existing embedding ID: doc150\n",
      "Add of existing embedding ID: doc150\n",
      "Insert of existing embedding ID: doc151\n",
      "Add of existing embedding ID: doc151\n",
      "Insert of existing embedding ID: doc152\n",
      "Add of existing embedding ID: doc152\n",
      "Insert of existing embedding ID: doc153\n",
      "Add of existing embedding ID: doc153\n",
      "Insert of existing embedding ID: doc154\n",
      "Add of existing embedding ID: doc154\n",
      "Insert of existing embedding ID: doc155\n",
      "Add of existing embedding ID: doc155\n",
      "Insert of existing embedding ID: doc156\n",
      "Add of existing embedding ID: doc156\n",
      "Insert of existing embedding ID: doc157\n",
      "Add of existing embedding ID: doc157\n",
      "Insert of existing embedding ID: doc158\n",
      "Add of existing embedding ID: doc158\n",
      "Insert of existing embedding ID: doc159\n",
      "Add of existing embedding ID: doc159\n",
      "Insert of existing embedding ID: doc160\n",
      "Add of existing embedding ID: doc160\n",
      "Insert of existing embedding ID: doc161\n",
      "Add of existing embedding ID: doc161\n",
      "Insert of existing embedding ID: doc162\n",
      "Add of existing embedding ID: doc162\n",
      "Insert of existing embedding ID: doc163\n",
      "Add of existing embedding ID: doc163\n",
      "Insert of existing embedding ID: doc164\n",
      "Add of existing embedding ID: doc164\n",
      "Insert of existing embedding ID: doc165\n",
      "Add of existing embedding ID: doc165\n",
      "Insert of existing embedding ID: doc166\n",
      "Add of existing embedding ID: doc166\n",
      "Insert of existing embedding ID: doc167\n",
      "Add of existing embedding ID: doc167\n",
      "Insert of existing embedding ID: doc168\n",
      "Add of existing embedding ID: doc168\n",
      "Insert of existing embedding ID: doc169\n",
      "Add of existing embedding ID: doc169\n",
      "Insert of existing embedding ID: doc170\n",
      "Add of existing embedding ID: doc170\n",
      "Insert of existing embedding ID: doc171\n",
      "Add of existing embedding ID: doc171\n",
      "Insert of existing embedding ID: doc172\n",
      "Add of existing embedding ID: doc172\n",
      "Insert of existing embedding ID: doc173\n",
      "Add of existing embedding ID: doc173\n",
      "Insert of existing embedding ID: doc174\n",
      "Add of existing embedding ID: doc174\n",
      "Insert of existing embedding ID: doc175\n",
      "Add of existing embedding ID: doc175\n",
      "Insert of existing embedding ID: doc176\n",
      "Add of existing embedding ID: doc176\n",
      "Insert of existing embedding ID: doc177\n",
      "Add of existing embedding ID: doc177\n",
      "Insert of existing embedding ID: doc178\n",
      "Add of existing embedding ID: doc178\n",
      "Insert of existing embedding ID: doc179\n",
      "Add of existing embedding ID: doc179\n",
      "Insert of existing embedding ID: doc180\n",
      "Add of existing embedding ID: doc180\n",
      "Insert of existing embedding ID: doc181\n",
      "Add of existing embedding ID: doc181\n",
      "Insert of existing embedding ID: doc182\n",
      "Add of existing embedding ID: doc182\n",
      "Insert of existing embedding ID: doc183\n",
      "Add of existing embedding ID: doc183\n",
      "Insert of existing embedding ID: doc184\n",
      "Add of existing embedding ID: doc184\n",
      "Insert of existing embedding ID: doc185\n",
      "Add of existing embedding ID: doc185\n",
      "Insert of existing embedding ID: doc186\n",
      "Add of existing embedding ID: doc186\n",
      "Insert of existing embedding ID: doc187\n",
      "Add of existing embedding ID: doc187\n",
      "Insert of existing embedding ID: doc188\n",
      "Add of existing embedding ID: doc188\n",
      "Insert of existing embedding ID: doc189\n",
      "Add of existing embedding ID: doc189\n",
      "Insert of existing embedding ID: doc190\n",
      "Add of existing embedding ID: doc190\n",
      "Insert of existing embedding ID: doc191\n",
      "Add of existing embedding ID: doc191\n",
      "Insert of existing embedding ID: doc192\n",
      "Add of existing embedding ID: doc192\n",
      "Insert of existing embedding ID: doc193\n",
      "Add of existing embedding ID: doc193\n",
      "Insert of existing embedding ID: doc194\n",
      "Add of existing embedding ID: doc194\n",
      "Insert of existing embedding ID: doc195\n",
      "Add of existing embedding ID: doc195\n",
      "Insert of existing embedding ID: doc196\n",
      "Add of existing embedding ID: doc196\n",
      "Insert of existing embedding ID: doc197\n",
      "Add of existing embedding ID: doc197\n",
      "Insert of existing embedding ID: doc198\n",
      "Add of existing embedding ID: doc198\n",
      "Insert of existing embedding ID: doc199\n",
      "Add of existing embedding ID: doc199\n",
      "Insert of existing embedding ID: doc200\n",
      "Add of existing embedding ID: doc200\n",
      "Insert of existing embedding ID: doc201\n",
      "Add of existing embedding ID: doc201\n",
      "Insert of existing embedding ID: doc202\n",
      "Add of existing embedding ID: doc202\n",
      "Insert of existing embedding ID: doc203\n",
      "Add of existing embedding ID: doc203\n",
      "Insert of existing embedding ID: doc204\n",
      "Add of existing embedding ID: doc204\n",
      "Insert of existing embedding ID: doc205\n",
      "Add of existing embedding ID: doc205\n",
      "Insert of existing embedding ID: doc206\n",
      "Add of existing embedding ID: doc206\n",
      "Insert of existing embedding ID: doc207\n",
      "Add of existing embedding ID: doc207\n",
      "Insert of existing embedding ID: doc208\n",
      "Add of existing embedding ID: doc208\n",
      "Insert of existing embedding ID: doc209\n",
      "Add of existing embedding ID: doc209\n",
      "Insert of existing embedding ID: doc210\n",
      "Add of existing embedding ID: doc210\n",
      "Insert of existing embedding ID: doc211\n",
      "Add of existing embedding ID: doc211\n",
      "Insert of existing embedding ID: doc212\n",
      "Add of existing embedding ID: doc212\n",
      "Insert of existing embedding ID: doc213\n",
      "Add of existing embedding ID: doc213\n",
      "Insert of existing embedding ID: doc214\n",
      "Add of existing embedding ID: doc214\n",
      "Insert of existing embedding ID: doc215\n",
      "Add of existing embedding ID: doc215\n",
      "Insert of existing embedding ID: doc216\n",
      "Add of existing embedding ID: doc216\n",
      "Insert of existing embedding ID: doc217\n",
      "Add of existing embedding ID: doc217\n",
      "Insert of existing embedding ID: doc218\n",
      "Add of existing embedding ID: doc218\n",
      "Insert of existing embedding ID: doc219\n",
      "Add of existing embedding ID: doc219\n",
      "Insert of existing embedding ID: doc220\n",
      "Add of existing embedding ID: doc220\n",
      "Insert of existing embedding ID: doc221\n",
      "Add of existing embedding ID: doc221\n",
      "Insert of existing embedding ID: doc222\n",
      "Add of existing embedding ID: doc222\n",
      "Insert of existing embedding ID: doc223\n",
      "Add of existing embedding ID: doc223\n",
      "Insert of existing embedding ID: doc224\n",
      "Add of existing embedding ID: doc224\n",
      "Insert of existing embedding ID: doc225\n",
      "Add of existing embedding ID: doc225\n",
      "Insert of existing embedding ID: doc226\n",
      "Add of existing embedding ID: doc226\n",
      "Insert of existing embedding ID: doc227\n",
      "Add of existing embedding ID: doc227\n",
      "Insert of existing embedding ID: doc228\n",
      "Add of existing embedding ID: doc228\n",
      "Insert of existing embedding ID: doc229\n",
      "Add of existing embedding ID: doc229\n",
      "Insert of existing embedding ID: doc230\n",
      "Add of existing embedding ID: doc230\n",
      "Insert of existing embedding ID: doc231\n",
      "Add of existing embedding ID: doc231\n",
      "Insert of existing embedding ID: doc232\n",
      "Add of existing embedding ID: doc232\n",
      "Insert of existing embedding ID: doc233\n",
      "Add of existing embedding ID: doc233\n",
      "Insert of existing embedding ID: doc234\n",
      "Add of existing embedding ID: doc234\n",
      "Insert of existing embedding ID: doc235\n",
      "Add of existing embedding ID: doc235\n",
      "Insert of existing embedding ID: doc236\n",
      "Add of existing embedding ID: doc236\n",
      "Insert of existing embedding ID: doc237\n",
      "Add of existing embedding ID: doc237\n",
      "Insert of existing embedding ID: doc238\n",
      "Add of existing embedding ID: doc238\n",
      "Insert of existing embedding ID: doc239\n",
      "Add of existing embedding ID: doc239\n",
      "Insert of existing embedding ID: doc240\n",
      "Add of existing embedding ID: doc240\n",
      "Insert of existing embedding ID: doc241\n",
      "Add of existing embedding ID: doc241\n",
      "Insert of existing embedding ID: doc242\n",
      "Add of existing embedding ID: doc242\n",
      "Insert of existing embedding ID: doc243\n",
      "Add of existing embedding ID: doc243\n",
      "Insert of existing embedding ID: doc244\n",
      "Add of existing embedding ID: doc244\n",
      "Insert of existing embedding ID: doc245\n",
      "Add of existing embedding ID: doc245\n",
      "Insert of existing embedding ID: doc246\n",
      "Add of existing embedding ID: doc246\n",
      "Insert of existing embedding ID: doc247\n",
      "Add of existing embedding ID: doc247\n",
      "Insert of existing embedding ID: doc248\n",
      "Add of existing embedding ID: doc248\n",
      "Insert of existing embedding ID: doc249\n",
      "Add of existing embedding ID: doc249\n",
      "Insert of existing embedding ID: doc250\n",
      "Add of existing embedding ID: doc250\n",
      "Insert of existing embedding ID: doc251\n",
      "Add of existing embedding ID: doc251\n",
      "Insert of existing embedding ID: doc252\n",
      "Add of existing embedding ID: doc252\n",
      "Insert of existing embedding ID: doc253\n",
      "Add of existing embedding ID: doc253\n",
      "Insert of existing embedding ID: doc254\n",
      "Add of existing embedding ID: doc254\n",
      "Insert of existing embedding ID: doc255\n",
      "Add of existing embedding ID: doc255\n",
      "Insert of existing embedding ID: doc256\n",
      "Add of existing embedding ID: doc256\n",
      "Insert of existing embedding ID: doc257\n",
      "Add of existing embedding ID: doc257\n",
      "Insert of existing embedding ID: doc258\n",
      "Add of existing embedding ID: doc258\n",
      "Insert of existing embedding ID: doc259\n",
      "Add of existing embedding ID: doc259\n",
      "Insert of existing embedding ID: doc260\n",
      "Add of existing embedding ID: doc260\n",
      "Insert of existing embedding ID: doc261\n",
      "Add of existing embedding ID: doc261\n",
      "Insert of existing embedding ID: doc262\n",
      "Add of existing embedding ID: doc262\n",
      "Insert of existing embedding ID: doc263\n",
      "Add of existing embedding ID: doc263\n",
      "Insert of existing embedding ID: doc264\n",
      "Add of existing embedding ID: doc264\n",
      "Insert of existing embedding ID: doc265\n",
      "Add of existing embedding ID: doc265\n",
      "Insert of existing embedding ID: doc266\n",
      "Add of existing embedding ID: doc266\n",
      "Insert of existing embedding ID: doc267\n",
      "Add of existing embedding ID: doc267\n",
      "Insert of existing embedding ID: doc268\n",
      "Add of existing embedding ID: doc268\n",
      "Insert of existing embedding ID: doc269\n",
      "Add of existing embedding ID: doc269\n",
      "Insert of existing embedding ID: doc270\n",
      "Add of existing embedding ID: doc270\n",
      "Insert of existing embedding ID: doc271\n",
      "Add of existing embedding ID: doc271\n",
      "Insert of existing embedding ID: doc272\n",
      "Add of existing embedding ID: doc272\n",
      "Insert of existing embedding ID: doc273\n",
      "Add of existing embedding ID: doc273\n",
      "Insert of existing embedding ID: doc274\n",
      "Add of existing embedding ID: doc274\n",
      "Insert of existing embedding ID: doc275\n",
      "Add of existing embedding ID: doc275\n",
      "Insert of existing embedding ID: doc276\n",
      "Add of existing embedding ID: doc276\n",
      "Insert of existing embedding ID: doc277\n",
      "Add of existing embedding ID: doc277\n",
      "Insert of existing embedding ID: doc278\n",
      "Add of existing embedding ID: doc278\n",
      "Insert of existing embedding ID: doc279\n",
      "Add of existing embedding ID: doc279\n",
      "Insert of existing embedding ID: doc280\n",
      "Add of existing embedding ID: doc280\n",
      "Insert of existing embedding ID: doc281\n",
      "Add of existing embedding ID: doc281\n",
      "Insert of existing embedding ID: doc282\n",
      "Add of existing embedding ID: doc282\n",
      "Insert of existing embedding ID: doc283\n",
      "Add of existing embedding ID: doc283\n",
      "Insert of existing embedding ID: doc284\n",
      "Add of existing embedding ID: doc284\n",
      "Insert of existing embedding ID: doc285\n",
      "Add of existing embedding ID: doc285\n",
      "Insert of existing embedding ID: doc286\n",
      "Add of existing embedding ID: doc286\n",
      "Insert of existing embedding ID: doc287\n",
      "Add of existing embedding ID: doc287\n",
      "Insert of existing embedding ID: doc288\n",
      "Add of existing embedding ID: doc288\n",
      "Insert of existing embedding ID: doc289\n",
      "Add of existing embedding ID: doc289\n",
      "Insert of existing embedding ID: doc290\n",
      "Add of existing embedding ID: doc290\n",
      "Insert of existing embedding ID: doc291\n",
      "Add of existing embedding ID: doc291\n",
      "Insert of existing embedding ID: doc292\n",
      "Add of existing embedding ID: doc292\n",
      "Insert of existing embedding ID: doc293\n",
      "Add of existing embedding ID: doc293\n",
      "Insert of existing embedding ID: doc294\n",
      "Add of existing embedding ID: doc294\n",
      "Insert of existing embedding ID: doc295\n",
      "Add of existing embedding ID: doc295\n",
      "Insert of existing embedding ID: doc296\n",
      "Add of existing embedding ID: doc296\n",
      "Insert of existing embedding ID: doc297\n",
      "Add of existing embedding ID: doc297\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    i = 1\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # print(filename)\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "                collection.add(\n",
    "                documents=text,\n",
    "                metadatas={\"filename\": filename},\n",
    "                ids=f\"doc{i}\",\n",
    "            )\n",
    "            i += 1\n",
    "\n",
    "\n",
    "\n",
    "directory_path = \"../dataset/aws-case-studies-blogs-dataset\"\n",
    "process_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0a2c17-9714-451a-a4ed-c8487cd5472d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"DynamoDB\"],\n",
    "    n_results=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a36a58-dac1-4133-ab00-cbc571d045cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['doc296', 'doc159', 'doc10', 'doc257', 'doc196']], 'distances': [[0.6806824207305908, 0.8134673833847046, 0.8582680821418762, 0.8845276832580566, 0.9456217885017395]], 'metadatas': [[{'filename': 'Improving Hiring Diversity and Accelerating App Development on AWS with Branch Insurance _ Case Study _ AWS.txt'}, {'filename': 'AWS Case Study - StreamAMG.txt'}, {'filename': 'Purple Technology Case Study _ AWS Step Functions.txt'}, {'filename': 'Game Studio Small Impact Games Runs Successful Alpha and Beta Tests Using Amazon GameLift _ Case Study _ AWS.txt'}, {'filename': 'Mobileye Cuts Costs Using Amazon EC2 _ Case Study _ AWS.txt'}]], 'embeddings': None, 'documents': [[\"Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale. DynamoDB offers built-in security, continuous backups, automated multi-Region replication, in-memory caching, and data import and export tools.  Learn more\\xa0»\\nAmazon Cognito provides an identity store that scales to millions of users, supports social and enterprise identity federation, and offers advanced security features to protect your consumers and business.\\xa0  Learn more\\xa0»\\nFrançais\\nEspañol\\nmore Black engineers and 26% more Hispanic or Latino engineers than industry averages\\nof typical cost for similarly sized startups \\nAWS AppSync creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data. \\n About Branch Insurance\\n 4 products\\n日本語\\n AWS Services Used\\n 6-month\\nlaunched in just 3 years with a team of fewer than 20 developers\\nHowever, offering this simplicity requires powerful infrastructure to process data quickly and store it efficiently and securely in compliance with regulations. Branch has been a serverless-native company on AWS since its founding in 2017 as a team of two. The startup wanted to use managed services to off-load as much of the infrastructure maintenance work as possible and reduce bespoke backend code to simplify its logic and improve scalability. “AWS has consistently provided better services that we can use to hand off more of the undifferentiated heavy lifting,” says Joe Emison, cofounder and chief technology officer of Branch. “By using AWS, we can focus our valuable time on what differentiates Branch.”\\xa0\\n한국어\\n Amazon DynamoDB\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\n \\nAs the startup grew, it also recognized several challenges with the existing job market. The company wanted to avoid the typical cycle of hiring a lot of senior developers because that practice excluded many talented developers from underrepresented groups in the software industry. “It can be difficult to find experienced developers who are willing to learn and adapt to the way your company wants to do things,” says Herndon. To break out of that constrained hiring market, Branch decided to focus on hiring junior developers and upskilling them through an in-house boot camp program based on its specific technology stack. \\nOpportunity |\\xa0Off-Loading Infrastructure Maintenance Work and Diversifying Hiring\\n Get Started\\n         \\n AWS AppSync\\nOne of the biggest benefits of building on AWS has been the ability to duplicate environments and run multiple environments on the same configurations for staging, development, and production. “With this setup, we can be much more confident in our ability to test,” says Herndon. “Developers have more time for working with the code because they don’t have to wait for a feature to be scheduled on a single staging environment.” Doing a full deployment on AWS now takes just 10–15 minutes for Branch. On average, the company deploys 5 times per week, and each time it saves a significant amount of time and resources that translate to increased developer productivity. In all, Branch has accelerated its development cycles by an estimated 6 months. “Using serverless technology on AWS, we’ve replaced what would be an entire team with a system that’s relatively cheap,” says Emison. The company estimates that it spends just 3 percent as much as similarly sized startups.\\xa0\\nMeanwhile, as developers come in from the boot camp, Branch creates new environments for them quickly on AWS. Further, new hires are better prepared to use the company’s serverless architecture so that they can more quickly get started building great products. The boot camp has also increased the diversity of Branch’s workforce. One-third of Branch’s engineering team is Black and one-third is Hispanic or Latino—much higher than the industry averages of 5 percent and 7 percent, respectively. In addition, Branch has 10 percent more female engineers than the industry average. “We’re trying to help these new hires acclimate more quickly to our team, but all of the skills we’re teaching are transferrable to other companies,” says Herndon. In that way, it’s also helping create a more diverse talent pool for all companies building in the cloud.\\xa0 \\n AWS Amplify\\nFast-growing insurance technology startup Branch set out to radically simplify the end-user experience for insurance customers by offering bindable prices based on just a couple of simple pieces of information—the customer’s name and address. “One of the things that makes us different is how quickly you can get a rate you can purchase,” says Ivan Herndon, vice president of engineering at Branch.\\xa0\\nBranch built an API hub using AWS AppSync, which creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data. The company also used a serverless architecture to empower its junior developers and diversify its workforce. As a result, Branch drastically reduced the amount of time and resources that it needed to deploy updates and maintain its technology stack. \\n中文 (繁體)\\nBahasa Indonesia\\nacceleration in app development velocity \\nWith this shift from hiring experience to nurturing expertise, Branch aimed to improve the diversity of its workforce while easing the onboarding process for new hires. It designed its boot camp curriculum to focus on the AWS services and serverless architecture that its developers use and build on every day. “Building on AWS works very well for us, and it scales seamlessly,” says Herndon. “We don’t have to worry about security compliance because it’s built into AWS services.” In addition, Branch leverages a fully-typed architecture, with TypeScript in its frontend code and a typed schema in its AppSync API hub, to create guardrails for its developers. Using\\xa0JavaScript (TypeScript) in both front and backends also makes it much easier for each developer to be a full-stack developer at Branch. \\nBranch Insurance (Branch) had goals for its internal development teams that were as ambitious as its efforts to provide uniquely simple insurance policies to its customers. The startup wanted to take an all-in approach to serverless architecture using Amazon Web Services (AWS) to make its infrastructure scalable, accelerate developer training, and simplify deployments.\\xa0\\n  Contact Sales \\nΡусский\\n 3%\\nعربي\\n中文 (简体)\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\n“Building a product on AWS is like doing it on ‘easy mode’ because there’s so much that’s simplified by using managed services,” says Emison. “We just write business logic and interfaces. That’s the great benefit of using AWS.” \\n           2022 \\n Overview\\nBuilding a product on AWS is like doing it on ‘easy mode’ because there’s so much that’s simplified by using managed services. We just write business logic and interfaces. That’s the great benefit of using AWS.”\\xa0\\n 28%\\nCustomer Stories / Financial Services \\n Amazon Cognito\\n Improving Hiring Diversity and Accelerating App Development on AWS with Branch Insurance\\nBranch Insurance is an insurance technology startup that provides simple insurance policies and comprehensive bundles to customers in 33 US states. The company was founded in 2017 in Columbus, Ohio. \\nEnglish\\nLearn how Branch Insurance accelerated app development using AWS AppSync. \\nmore female engineers than the industry average\\nDeutsch\\n 10%\\nBranch uses AWS AppSync as the foundation for its backend infrastructure and API service. AWS AppSync receives all the requests from the company’s website and mobile app, filters out malicious requests, makes sure each request is properly formatted, and finally initiates the proper business logic. The company also manages the authorization flow using libraries from AWS Amplify, open-source client libraries that developers can use to build cloud-powered mobile and web apps. “Branch’s entire backend, including all business logic and transactional data, runs on AWS AppSync,” says Emison. “By connecting AWS AppSync to AWS Amplify, the amount we have to deal with operations is extremely minimal.”\\xa0\\nOutcome |\\xa0Building Products on 'Easy Mode' Using AWS Services\\nTiếng Việt\\nSolution |\\xa0Using AWS AppSync Accelerated App Development Cycles by 6 Months for Branch\\nItaliano\\nไทย\\nBranch uses the scalability of Amazon DynamoDB, a key-value and document database that delivers single-digit millisecond performance at virtually any scale, to handle as much traffic as it needs. Meanwhile, the startup stores all member information on Amazon Cognito, which businesses can use to add sign-up, sign-in, and access control to web and mobile apps quickly and easily. Branch has made user authentication effortless by using AWS AppSync to route each user login request to Amazon Cognito. “One of the magical parts of AWS AppSync is how well it connects to Amazon Cognito to automatically respond to authentication requests,” says Emison.\\xa0\\nTürkçe\\nIn just 3 years, Branch launched four insurance products—home, auto, renters, and umbrella insurance—in 33 US states. And the company did that with fewer than 20 full-time developers. As it continues to grow and hire new developers through its custom boot camp, it plans even more innovative features.\\xa0\\nJoe Emison Co-Founder and Chief Technology Officer \\nLearn more\\xa0»\\nAWS Amplify is a complete solution that lets frontend web and mobile developers easily build, ship, and host full-stack applications on AWS, with the flexibility to leverage the breadth of AWS services as use cases evolve. No cloud expertise needed.  Learn more\\xa0»\\nPortuguês\", 'Français\\nAmazon Kinesis Data Firehose is the easiest way to reliably load streaming data into data lakes, data stores, and analytics services. It can capture, transform, and deliver streaming data to Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, generic HTTP endpoints, and service providers like Datadog, New Relic, MongoDB, and Splunk. \\nAmazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale. It\\'s a fully managed, multi-region, multi-active, durable database with built-in security, backup and restore, and in-memory caching for internet-scale applications. \\nThe flawless start to the season was greatly appreciated by StreamAMG\\'s customers, according to Andrew and raised the company\\'s profile across the industry: \"In the OTT industry reputation is key and our ability to consistently deliver scalable and resilient platforms has afforded us such a dependable reputation,\" he says.\\nEspañol\\nLive sports streaming provider StreamAMG quickly realized early in the year that the 2020 English football calendar would be radically different from what had gone before.\\n\"We started working internally to formulate a plan which would deliver a technical solution that could scale above and beyond our requirements.\"\\nWith COVID-19 disruption growing and matches played behind closed doors, the company began planning for a very different season – one where more users than ever would rely on its over-the-top (OTT) platforms to support their club, and clubs would increasingly rely on streamed matches as a revenue source.\\nAWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers, creating workload-aware cluster scaling logic, maintaining event integrations, or managing runtimes. With Lambda, you can run code for virtually any type of application or backend service - all with zero administration. \\n日本語\\n StreamAMG Scores Record Viewership and Uninterrupted Delivery\\nTo achieve that, the teams undertook a comprehensive application transformation, replacing the most important components of the previous application with a cloud-native system that underpinned the load-bearing parts of StreamAMG\\'s products with microservices and serverless technologies based on AWS.\\n A New Environment, a New Infrastructure\\nAgility & Performance \\n Get Started\\n한국어\\n \\n Amazon Lambda\\n A Great Time to Score\\n Amazon CloudFront\\n AWS Services Used\\n中文 (繁體)\\nBahasa Indonesia\\nThe company delivered 2.9 million streams, watched by hundreds of thousands of fans, and an overall data uplift of 500 percent – all without a hitch and with no updates to the architecture needed.\\nServices include AWS API Gateway, AWS Lambda, Amazon CloudFront, Amazon DynamoDB, and Amazon ElastiCache for Memcached. StreamAMG also adopted Amazon Kinesis Data Firehose to collect and process actions and user activity in real-time, and stream the data for storage later on. \\nStreamAMG enables organisations across sports, media and betting to deliver video content at scale and offer exceptional streaming experiences.\\nΡусский\\nعربي\\nAvailability \\n中文 (简体)\\n\"Being in the live sports business, failure is not really an option at all. Even going down for 10 seconds is going to impact tens of thousands or hundreds of thousands of users simultaneously. Scale and resiliency were definitely the two most important elements for us,\" Andrew De Bono, StreamAMG\\'s CTO, says.\\xa0\\nTo support the unprecedented load the new season was likely to bring, StreamAMG began to reexamine its platform architecture to cope with the challenges ahead.\\n Benefits of AWS\\n Scalability, Elasticity, Cost\\nTo accommodate the uncertain demands of the season, the team wanted to create an infrastructure that could cope with the heaviest loads and still scale with demand. When the season began, they proved they had done just that: despite the massive spike in usage, StreamAMG delivered all matches with near zero downtime or interruption.\\nCost Optimization & Cost Savings \\nAs well as coping with unexpected demand, the scalability of the new system made a significant difference to StreamAMG\\'s cost optimization, raising its performance ceiling without raising running costs. Due to the nature of live sports, StreamAMG\\'s system might receive only light usage the majority of the time when no live matches are being played, and then see a huge spike in demand on matchday.\\nTürkçe\\nIn the OTT industry reputation is key and our ability to consistently deliver scalable and resilient platforms has afforded us such a dependable reputation.\"  \\nEnglish\\nAmazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-friendly environment. \\nThe previous system had to be primed to deal with maximum usage 24/7, even when the company knew 90 percent of the time that capacity wouldn\\'t be required. That all changed with AWS.\\nElasticity \\n  Learn more \\nDeutsch\\n Amazon DynamoDB\\nTiếng Việt\\n Amazon Kinesis Data Firehose\\nIn the first minutes and hours of the season, the StreamAMG team was able to monitor how the system was dealing with the matches through Amazon CloudWatch, which provided visibility on both the platform and the traffic in real time, allowing the company to be fully aware and in control of the application.\\nAndrew De Bono CTO, StreamAMG  \\nItaliano\\nไทย\\n\"We really are paying for every single user on our platform, nothing less and nothing more, so we really could align the cost with the actual usage, rather than taking on massive capex hits to support the increased capacity on our application,” says De Bono.\\xa0 \\n About StreamAMG\\n2020\\nLearn more\\xa0»\\nThe company needed a set-up agile enough to deal with the uncertainties of the new situation, while still managing potentially millions of hits per minute with zero failover. While the streaming part of the business had to operate with the highest levels of availability, the company also needed to ensure its user membership, payment and entitlement management systems could easily handle the predicted jump in demand. And both elements needed to be able to scale to traffic levels that could be 400 percent to 500 percent of what the company might see in a normal season.\\nA project of similar scale and significance might be expected to take several months, even without the disruption caused by COVID-19. But working to a hard deadline of the new season kickoff, the project was delivered in just 12 weeks, thanks to the close collaboration between the AWS and StreamAMG teams.\\nCompanies of all sizes across all industries are transforming their businesses every day using AWS. Start your own AWS Cloud journey today. \\nPortuguês', 'In addition to better compliance with regulations through improved transparency, the Purple IT team has improved and accelerated software development processes using AWS.\\nAWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend service without provisioning or managing servers. You can trigger Lambda from over 200 AWS services and software as a service (SaaS) applications, and only pay for what you use.File processing\\xa0Stream processing\\xa0Web applications\\xa0IoT backends\\xa0Mobile backends.  \\nFrançais\\n Benefits of AWS\\nJan Červinka Director of Engineering, Purple Technology \\nEspañol\\n Amazon EC2\\nThe Czech-based company builds apps that complement online trading platforms and support the changing and demanding needs of brokers. Purple’s solution enables tens of thousands of clients to trade many billions of dollars of assets each month.\\n日本語\\nIn addition, brokers and traders must comply with rules that change from country to country. These rules are subject to sudden changes in regulation—and even to evolving legal interpretations.\\n Get Started\\n한국어\\nAmazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale. DynamoDB offers built-in security, continuous backups, automated multi-Region replication, in-memory caching, and data import and export tools. \\nIncreases transparency of complex processes\\n Purple Technology Responds Rapidly to Changing Regulations and Customer Needs Using AWS\\n \\n Amazon Lambda\\nPurple needed a more transparent and effective way to manage the complex ruleset that governed customer onboarding and allow it to respond more quickly to changing rules. It found the solution it needed using AWS Step Functions, a low-code, visual workflow service that developers can use to build applications. “Onboarding involves complex processes that we have to be able to understand and update easily,” says Jan Červinka, director of engineering at Purple Technology. “We can now map and design all of these processes using AWS Step Functions.”\\nTo register new trading accounts with brokers, users need to go through a number of steps to qualify. The registration process checks many conditions, some via API, to confirm that the new customer is not disqualified from trading. Purple’s onboarding process also supports Know Your Customer (KYC) user verification and anti-money laundering (AML) processes.\\n Amazon Step functions\\n AWS Services Used\\nPurple wanted greater transparency and control to improve its services and reduce the in-house resources required to maintain its applications. Using Amazon Web Services (AWS), Purple found a way to easily manage changes to the backend ruleset and make the ruleset more transparent to internal and external stakeholders.\\n中文 (繁體)\\nBahasa Indonesia\\nWhile the Purple application has a user-friendly front end, the backend was a complex code base. Changes to the rules required developers to delve into the code to make amendments and make sure the app was compliant. Questions from product managers about the rules and processes required developers to create diagrams that would quickly become outdated.\\n  Contact Sales \\nΡусский\\nعربي\\n中文 (简体)\\nTo simplify this maintenance process further, Purple built a Slack extension to allow rules to be repaired and amended from the messaging platform. This also means customer service teams at brokers can operate the tool and provide a responsive service to their own customers. Using AWS we have significantly improved the self-service capabilities of the customer support teams,” says Červinka. “That leads to a much faster time to resolution of certain issues customers may encounter.”\\n About Purple Technology \\nLearn more\\xa0»\\nBuild and run applications without thinking about servers.\\xa0Severless on AWS \\nResponding to Changing Regulatory Changes\\nOn AWS, Purple also has greater freedom to innovate. Using AWS infrastructure as code means that developers can spin up test environments to work on new features. These test environments consume fewer resources than production sites. “Using AWS we can experiment and play with new ideas. And we have the confidence that we can stay on top of the changes to regulations through better control and transparency with AWS services,” says Pýrek. \\nUsing AWS Step Functions, the company always has up-to-date product documentation as it is automatically generated. Now if a regulator or legal counsel asks to review the application’s processes, Purple can share the documentation to demonstrate how it complies. “It’s much easier to produce visual reports and diagrams for our compliance stakeholders,” says Červinka. “That frees up IT teams from having to provide complex, time-intensive—and not really fun—support so they can instead focus on building new features.”\\nReduces maintenance burden on developer team\\nTürkçe\\nFinTech company Purple Technology builds applications and services for brokerage firms to onboard customers efficiently. End users self-manage their accounts and portfolios, which leaves brokerages free to focus on core functions such as client services and risk management. Users creating new trading accounts with brokers need to follow a stringent onboarding process that complies with complex rules and regulations to verify their identities. Using AWS, Purple has simplified the way these rulesets are coded into the app, making it easier for non-technical employees to manage the application and keep on top of changing regulations. \\nEnglish\\nBut managing those rules was a complex and time-consuming process, often requiring developer resources that would be better spent on product innovation, not maintenance.\\nResolves software issues more efficiently\\nAmazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.\\nDevelopers can also devote more time to improving the platform rather than troubleshooting issues, because AWS Step Functions has reduced the time required for debugging. This has increased the team’s speed of development.\\nDeutsch\\n Amazon DynamoDB\\nTrading and investing online relies on transparency, and trust in the platform, in the brokers, and in the identity of traders. Purple Technology helps build that trust.\\nTiếng Việt\\nItaliano\\nไทย\\nUsing AWS, we have greater visibility into our complex processes, making them simple to visualize, manage, and update. This means we can be more responsive to any new or changing regulations and to customer needs.” \\nBoosts speed of development of new features \\nCommunication with business decision-makers on new software features is now more productive. “It’s easy to read and modify AWS Step Functions,” says Filip Pýrek, serverless architect at Purple Technology. “We use it for prototyping when designing features, so non-technical colleagues can understand and discuss new processes.”\\n2022\\nBased in the Czech Republic, Purple Technology is a financial technology company founded in 2011. It provides an online trading platform for brokerages and their clients around the world. \\n Faster Development and Product Maintenance\\nAs a FinTech company, Purple’s solution has to comply with a huge number of legal and regulatory rules that vary from territory to territory and are subject to constant change. Purple’s solution needs to accurately capture these rules to run checks during new trader account registrations.\\nAWS Step Functions is a low-code, visual workflow service that developers use to build distributed applications, automate IT and business processes, and build data and machine learning pipelines using AWS services. Workflows manage failures, retries, parallelization, service integrations, and observability so developers can focus on higher-value business logic.  \\nPortuguês\\nUsing AWS Step Functions, Purple Technology maps out the workflows for each process so that it can easily fix any issues and demonstrate to regulators how customer checks are carried out. In addition, rather than drawing on developers to make changes, Purple can use trained, non-technical people to carry out maintenance.', 'Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale. DynamoDB offers built-in security, continuous backups, automated multi-Region replication, in-memory caching, and data import and export tools.  Learn more\\xa0»\\nFrançais\\nSIG was founded in 2012 and is based in Leicester, England. It is working on developing tactile, first-person, looter-shooter games and has been involved with 22 different gaming projects. The gaming studio’s focus is on making player-centric games with a small team of 12 developers.\\n           2023 \\nEspañol\\n AWS AppSync\\nto deploy regional infrastructure \\nAlthough SIG frequently hit its predefined bandwidth limits during the testing phases of Marauders, it was able to expand quickly as needed. Given the company’s size, launching Marauders would not have been as successful without the flexibility afforded by AWS. “You hear stories about games where the whole system will just bottom out because of capacity, but we’ve never seen that or been close to it,” says Rowbotham. “Even in our busiest points, we were matchmaking in 30 seconds, and everyone was having a great time. Scaling was never a concern using AWS.” On AWS, SIG can monitor new players joining its game worldwide and can quickly deploy infrastructure when necessary. “Not only were we spreading out horizontally, but we were also dealing with vertical capacity issues, which were painless to resolve,” says Rowbotham.\\n日本語\\n Amazon GameLift\\nCustomer Stories / Games \\n Get Started\\n한국어\\nOverview | Opportunity | Solution | Outcome | AWS Services Used \\n \\n         \\n ≤ 30 second\\n AWS Services Used\\n Game Studio Small Impact Games Runs Successful Alpha and Beta Tests Using Amazon GameLift\\n中文 (繁體)\\nBahasa Indonesia\\nSmall Impact Games (SIG), a small, independent computer video game development company, wanted to launch Alpha and Beta testing for its new game: Marauders. However, SIG believed that the scale of these tests would go far beyond that of any game that it had previously created and supported. The company wanted a solution that would give it the ability to retain primary control over its infrastructure. Because of the performance and scalability that these tests required, and the large number of concurrent users that were expected worldwide, the company decided to use a suite of Amazon Web Services (AWS) solutions to support the game. Now SIG has access to the bandwidth that it requires while maintaining the control that it wants.\\n  Contact Sales \\nΡусский\\n Increased flexibility\\nعربي\\nWhen SIG began working on Marauders, a first-person multiplayer game, the studio expected the demand from participation rates would overwhelm the testing of the game. At the start of the Marauders testing period, SIG wanted to prepare for fluctuations in traffic by investing in a highly scalable infrastructure solution that would be simple to manage and deliver an optimal gaming experience. To meet these goals, the SIG team decided to use Amazon GameLift, a solution for dedicated game server hosting that deploys, operates, and scales cloud servers for multiplayer games. “We went all in using Amazon GameLift for Marauders,” says James Rowbotham, lead developer at SIG. “GameLift is a service that gave us the ability to do specifically what we wanted to do.” SIG’s service upgrade ultimately proved to be a wise choice because the tests far exceeded expectations; the closed Alpha test logged 3,000 concurrent users, and the closed Beta test logged around 7,000 concurrent users.\\n中文 (简体)\\nOpportunity | Searching for a Scalable, Reliable Infrastructure Solution for Small Impact Games\\n 7,000\\nIn addition to retaining control over its infrastructure, SIG was able to improve the performance of Marauders while using AWS. The company wanted to add a persistent gear aspect to the game so that players could keep the gear that they collected across different game sessions. The technical demands and capacity that this feature required led the SIG team to adopt Amazon DynamoDB, a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at virtually any scale. SIG also wanted to use the data that it collected to improve the game for players. For this purpose, the SIG team chose Amazon QuickSight, which empowers everyone in an organization to understand data by asking questions in natural language, exploring through interactive dashboards, or automatically looking for patterns and outliers powered by machine learning.\\n\\xa0\\n Overview\\n Maintained control\\n Amazon DynamoDB\\nStarting in July 2020, a core team of three lead developers transformed SIG’s game development environment in 16 months, adopting several fully managed AWS services, including Amazon GameLift and AWS AppSync, which creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data. The scalability, elasticity, and control offered by these services worked perfectly for the small team that was working on Marauders, and the gaming studio scaled its infrastructure to support over 7,000 concurrent players during one of its tests. Moreover, SIG gained the ability to control its infrastructure in house so that it did not depend on a third party to perform the actions required to keep its system running. “As we dug deeper into AWS, we gained more knowledge, and we retained control. Using AWS, we can be fully autonomous,” says Mitchell Small, managing director at SIG.\\nTürkçe\\nEnglish\\nAmazon GameLift deploys and manages dedicated game servers hosted in the cloud, on-premises, or through hybrid deployments. GameLift provides a low-latency and low-cost solution that scales with fluctuating player demand.\\nThe success of the Marauders Alpha and Beta tests—marked by the sale of more than 80,000 copies of the game as of September 2022—has positioned SIG to become a significant player and successful developer in its market. Marauders has been featured on the home page of Team17, a video game developer and SIG’s publisher. Additionally, as of September 2022, Marauders was a top Wishlist item on Steam, a popular video game digital distribution service and storefront, and the game’s Discord channel had grown to over 36,000 members.\\nSolution | Using Amazon GameLift to Scale Testing to a Global Fan Base\\xa0\\nJames Rowbotham Lead Developer, Small Impact Games \\nSmall Impact Games is a small, independent computer video game development company that primarily creates tactile, first-person, looter-shooter games.\\nDeutsch\\nconcurrent users \\nLearn how game studio Small Impact Games supported Alpha and Beta testing for its new video game using Amazon GameLift.\\nTiếng Việt\\nAWS AppSync creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data.  Learn more\\xa0»\\nItaliano\\nไทย\\nAmazon QuickSight powers data-driven organizations with unified business intelligence (BI) at hyperscale. With QuickSight, all users can meet varying analytic needs from the same source of truth through modern interactive dashboards, paginated reports, embedded analytics, and natural language queries.  Learn more\\xa0»\\nSIG’s immediate goal is to focus on the early-access release of Marauders. The company is all in on AWS following the success of the Marauders Alpha and Beta tests. Going forward, SIG sees the potential for more growth with the flexibility and speed that using AWS provides. The company wants to use more events and tournaments to publicize its games, and it believes that AWS is the solution to make that happen. “I’m so glad that we ended up fully embracing AWS. It gives you so much for such little work, which is perfect for us,” says Rowbotham.\\nLearn more\\xa0»\\n About Small Impact Games\\nover the development environment \\n Amazon QuickSight\\nEven in our busiest points, we were matchmaking in 30 seconds, and everyone was having a great time. Scaling was never a concern using AWS.”\\nmatchmaking during peak times \\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\nPortuguês\\nOutcome | Becoming a Larger Player in the Gaming Market Using AWS', 'Opportunity | Determining the Need for Increased Compute Power at a Reduced Cost\\nFrançais\\nThe REM team updates the map in near real time: accessing, changing, rebuilding, and stitching together more than 2 million kilometers of drivable paths with detail down to the level of a single stop sign. Each map in development is saved to Amazon Aurora, which is designed for unparalleled high performance and availability at a global scale with full MySQL and PostgreSQL compatibility. “We chose Aurora because it gave us the ability to work at a large scale without having to deal with a lot of maintenance or trying to optimize it ourselves,” says Reisman. “We get excellent performance out of the box.”\\nAmazon S3 is an object storage service offering industry-leading scalability, data availability, security, and performance.\\nCustomer Stories /\\xa0Automotive \\nEspañol\\nMobileye is now able to use a single, highly scalable, self-managed Apache Spark cluster to map the entirety of Europe, using crowdsourced RSD that is tailored to the functionality of autonomous vehicles. Crowdsourced data is stored in Amazon Simple Storage Service (Amazon S3), an object storage service offering high scalability, data availability, security, and performance. “Our DevOps team worked alongside the AWS team to figure out how to store huge datasets on Amazon S3 in the most cost-effective way, giving developers access to an almost infinite number of scenarios while not breaking the bank,” says Reisman. The REM team has also begun using the Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering) storage class, which delivers automatic storage cost savings when data access patterns change, without performance impact or operational overhead. “Within Mobileye, Amazon S3 Intelligent-Tiering has been used for quite some time and has shown significant cost reductions,” says Reisman. “From the deep analysis we did alongside the AWS team, it looks like REM will be substantially reducing costs by using this as well.”\\n Solution | Optimizing Costs for Compute and Storage\\n日本語\\n  Contact Sales \\n 2022\\nWorking alongside AWS subject matter experts, the REM team planned a load test to address the scalability issue of a single cluster. The load test would attempt to map significant parts of Germany using the company’s actual operational code and real RSD information fed into a single cluster of Apache Spark, an open-source, distributed processing system used for big data workloads. The team started small, tweaking the parameters and improving any bottlenecks. The load test involved several stages, gradually increasing the compute until it peaked at 1,300 parallel cells running on 250,000 vCPUs on a single Apache Spark cluster without issue, a significant improvement over REM’s previous maximum capacity of 60,000 vCPUs. Mobileye could map the entire country of Germany in just 2–4 days running on 200,000 vCPUs. “Using AWS, the same map was considerably cheaper to create than before, and it took less than half the time to complete the same area,” says Pini Reisman, director of REM cloud application at Mobileye. “This was achieved by trying to push the envelope and figuring out what was limiting us from running this at the scale that we wanted in one Apache Spark cluster.”\\n한국어\\n Mobileye Optimizes Ability to Build Crowdsource HD Maps and Cut Costs Using Amazon EC2 Spot Instances\\nOrganizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\\n \\nstorage costs reduced \\n 250,000\\n Get Started\\nIn 2022, the company plans to map the entirety of Europe, which will require the system to scale up to 200,000 concurrent vCPUs for 20 days—96 million vCPU hours in total. “It’s not that our architecture has changed,” says Reisman. “It’s that we managed to break the boundaries that we had before.”\\n AWS Services Used\\n Outcome | Expanding REM Functionality Further\\n Large dataset\\n Reduced\\n中文 (繁體)\\nBahasa Indonesia\\nAs a leading supplier of technologies for driving systems, Mobileye needed a way to create high-definition (HD) maps that provided a full set of features for driving-assist technologies and self-driving cars at an affordable cost. The creation of HD driving maps for an entire continent requires enormous compute power that must simultaneously collect data from vehicles and continuously update existing maps, a process that can quickly become unwieldy with soaring costs.\\n About Mobileye \\nMobileye’s Road Experience Management (REM) group, which is responsible for the creation of its HD maps, addressed these challenges by developing a complex microservices architecture using Amazon Web Services (AWS). The solution is powered by Amazon Elastic Compute Cloud (Amazon EC2), which offers secure and resizable compute capacity for virtually any workload. Using a suite of managed services from AWS, Mobileye could simplify its infrastructure, reduce operational overhead, and scale to more than 250,000 virtual CPUs (vCPUs) running concurrently at a fraction of the cost.\\nΡусский\\nعربي\\n中文 (简体)\\nLearn more\\xa0» \\nFounded in 1999, Mobileye develops technology for advanced driver assistance and autonomous driving systems. The company collects data for its mapping by crowdsourcing: vehicles navigating the roads send back road segment data (RSD) that the system ingests and processes. Mobileye extracts only the valuable information from the RSD, a process that minimizes the size and processing cost of the data. By early 2019, the REM team started receiving millions of RSD files daily, which was too much data to run on one compute cluster. As a result, the team had to split the continent of Europe into four disjointed areas and scale, debug, and monitor each one. The overhead of running four clusters contributed to a significant operational challenge that added to the cost and required the team to stitch the clusters together to achieve full functionality.\\n Overview\\n Amazon Aurora\\nMobileye develops technology for advanced driver assistance and autonomous driving systems. The company was founded in Israel in 1999 and is a leading provider of both camera-based driving-assist systems and solutions for self-driving systems. \\n Amazon Simple Storage Service (Amazon S3)\\nTürkçe\\nEnglish\\nvCPUs on a single Apache Spark cluster \\nAmazon Aurora provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other AWS services.  Learn more\\xa0»\\nhigh-performance compute costs \\nPini Reisman Director of REM Cloud Application, Mobileye \\nDeutsch\\n Amazon S3 Intelligent-Tiering \\nTiếng Việt\\nTo manage the cost of running hundreds of thousands of vCPUs, the company used Amazon EC2 Spot Instances, which let companies take advantage of unused Amazon EC2 capacity and receive up to a 90 percent discount compared with On-Demand prices. But because AWS can reclaim Spot Instances when it needs the capacity in exchange for steep discounts, Mobileye runs its fleet of Spot Instances across many Availability Zones, one or more discrete data centers with redundant power, networking, and connectivity in an AWS Region. Additionally, the fleet consists of many Amazon EC2 instance types to diversify traffic and minimize interruptions, with priority given to the largest machines within a single Availability Zone. The solution uses primarily R-instance types for optimal CPU and memory rationing and cost. It prioritizes 24xlarge instances within the R-instance family before using 16xlarge, then 8xlarge, and so forth before opening a new Availability Zone. “Using Spot Instances, we have a very big discount in our enterprise account,” says Ofer Eliassaf, Mobileye’s cloud infrastructure group lead.\\nUsing AWS, the same map was considerably cheaper to create than before, and it took less than half the time to complete the same area.”  \\nOverview | Opportunity | Solution | Outcome | AWS Services Used\\xa0 \\nItaliano\\nไทย\\nS3 Intelligent-Tiering is the only cloud storage class that delivers automatic storage cost savings when data access patterns change, without performance impact or operational overhead.\\nAmazon EC2 Spot Instances let you take advantage of unused EC2 capacity in the AWS cloud.\\nLearn more\\xa0»\\n Amazon EC2 Spot Instances\\nPortuguês']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39cb8051-2c66-4393-9e28-2e6851f07b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066c159d-77ee-48a1-bc7b-b755732e5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Downloading shards: 100%|██████████| 8/8 [02:25<00:00, 18.18s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:41<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    ")\n",
    "#\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=READER_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5e8af02-2f63-448e-8139-d78826a78a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "{context}\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: {question}</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cce990f3-409e-4bf3-8f18-13bc5d24b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting retrieval for user_query='How can I use Lambda?'...\n",
      "\n",
      "==================================Top k documents==================================\n",
      "filename: [{'filename': 'Improving Hiring Diversity and Accelerating App Development on AWS with Branch Insurance _ Case Study _ AWS.txt'}, {'filename': 'AWS Case Study - StreamAMG.txt'}, {'filename': 'Purple Technology Case Study _ AWS Step Functions.txt'}, {'filename': 'Game Studio Small Impact Games Runs Successful Alpha and Beta Tests Using Amazon GameLift _ Case Study _ AWS.txt'}, {'filename': 'Mobileye Cuts Costs Using Amazon EC2 _ Case Study _ AWS.txt'}]\n",
      "file_id: ['doc296', 'doc159', 'doc10', 'doc257', 'doc196']\n",
      "\n",
      "==================================Top document==================================\n",
      "filename: Improving Hiring Diversity and Accelerating App Development on AWS with Branch Insurance _ Case Study _ AWS.txt\n",
      "file_id: doc296\n"
     ]
    }
   ],
   "source": [
    "user_query = \"How can I use Lambda?\"\n",
    "k=5\n",
    "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
    "print(\"\\n==================================Top k documents==================================\")\n",
    "topk_retrieved_filename =  results['metadatas'][0][:k]\n",
    "topk_retrieved_file_id =  results['ids'][0][:k]\n",
    "topk_retrieved_file =  results['documents'][0][:k]\n",
    "print(f\"filename: {topk_retrieved_filename}\\nfile_id: {topk_retrieved_file_id}\")\n",
    "print(\"\\n==================================Top document==================================\")\n",
    "retrieved_filename =  results['metadatas'][0][0]\n",
    "retrieved_file_id =  results['ids'][0][0]\n",
    "retrieved_file =  results['documents'][0][0]\n",
    "print(f\"filename: {retrieved_filename['filename']}\\nfile_id: {retrieved_file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e86478cb-1494-4d89-b975-e0f92e5d72d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "\n",
      "Extracted documents:\n",
      "Document 0:::\n",
      "Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale. DynamoDB offers built-in security, continuous backups, automated multi-Region replication, in-memory caching, and data import and export tools.  Learn more »\n",
      "Amazon Cognito provides an identity store that scales to millions of users, supports social and enterprise identity federation, and offers advanced security features to protect your consumers and business.   Learn more »\n",
      "Français\n",
      "Español\n",
      "more Black engineers and 26% more Hispanic or Latino engineers than industry averages\n",
      "of typical cost for similarly sized startups \n",
      "AWS AppSync creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data. \n",
      " About Branch Insurance\n",
      " 4 products\n",
      "日本語\n",
      " AWS Services Used\n",
      " 6-month\n",
      "launched in just 3 years with a team of fewer than 20 developers\n",
      "However, offering this simplicity requires powerful infrastructure to process data quickly and store it efficiently and securely in compliance with regulations. Branch has been a serverless-native company on AWS since its founding in 2017 as a team of two. The startup wanted to use managed services to off-load as much of the infrastructure maintenance work as possible and reduce bespoke backend code to simplify its logic and improve scalability. “AWS has consistently provided better services that we can use to hand off more of the undifferentiated heavy lifting,” says Joe Emison, cofounder and chief technology officer of Branch. “By using AWS, we can focus our valuable time on what differentiates Branch.” \n",
      "한국어\n",
      " Amazon DynamoDB\n",
      "Overview | Opportunity | Solution | Outcome | AWS Services Used \n",
      " \n",
      "As the startup grew, it also recognized several challenges with the existing job market. The company wanted to avoid the typical cycle of hiring a lot of senior developers because that practice excluded many talented developers from underrepresented groups in the software industry. “It can be difficult to find experienced developers who are willing to learn and adapt to the way your company wants to do things,” says Herndon. To break out of that constrained hiring market, Branch decided to focus on hiring junior developers and upskilling them through an in-house boot camp program based on its specific technology stack. \n",
      "Opportunity | Off-Loading Infrastructure Maintenance Work and Diversifying Hiring\n",
      " Get Started\n",
      "         \n",
      " AWS AppSync\n",
      "One of the biggest benefits of building on AWS has been the ability to duplicate environments and run multiple environments on the same configurations for staging, development, and production. “With this setup, we can be much more confident in our ability to test,” says Herndon. “Developers have more time for working with the code because they don’t have to wait for a feature to be scheduled on a single staging environment.” Doing a full deployment on AWS now takes just 10–15 minutes for Branch. On average, the company deploys 5 times per week, and each time it saves a significant amount of time and resources that translate to increased developer productivity. In all, Branch has accelerated its development cycles by an estimated 6 months. “Using serverless technology on AWS, we’ve replaced what would be an entire team with a system that’s relatively cheap,” says Emison. The company estimates that it spends just 3 percent as much as similarly sized startups. \n",
      "Meanwhile, as developers come in from the boot camp, Branch creates new environments for them quickly on AWS. Further, new hires are better prepared to use the company’s serverless architecture so that they can more quickly get started building great products. The boot camp has also increased the diversity of Branch’s workforce. One-third of Branch’s engineering team is Black and one-third is Hispanic or Latino—much higher than the industry averages of 5 percent and 7 percent, respectively. In addition, Branch has 10 percent more female engineers than the industry average. “We’re trying to help these new hires acclimate more quickly to our team, but all of the skills we’re teaching are transferrable to other companies,” says Herndon. In that way, it’s also helping create a more diverse talent pool for all companies building in the cloud.  \n",
      " AWS Amplify\n",
      "Fast-growing insurance technology startup Branch set out to radically simplify the end-user experience for insurance customers by offering bindable prices based on just a couple of simple pieces of information—the customer’s name and address. “One of the things that makes us different is how quickly you can get a rate you can purchase,” says Ivan Herndon, vice president of engineering at Branch. \n",
      "Branch built an API hub using AWS AppSync, which creates serverless GraphQL and Pub/Sub APIs that simplify application development through a single endpoint to securely query, update, or publish data. The company also used a serverless architecture to empower its junior developers and diversify its workforce. As a result, Branch drastically reduced the amount of time and resources that it needed to deploy updates and maintain its technology stack. \n",
      "中文 (繁體)\n",
      "Bahasa Indonesia\n",
      "acceleration in app development velocity \n",
      "With this shift from hiring experience to nurturing expertise, Branch aimed to improve the diversity of its workforce while easing the onboarding process for new hires. It designed its boot camp curriculum to focus on the AWS services and serverless architecture that its developers use and build on every day. “Building on AWS works very well for us, and it scales seamlessly,” says Herndon. “We don’t have to worry about security compliance because it’s built into AWS services.” In addition, Branch leverages a fully-typed architecture, with TypeScript in its frontend code and a typed schema in its AppSync API hub, to create guardrails for its developers. Using JavaScript (TypeScript) in both front and backends also makes it much easier for each developer to be a full-stack developer at Branch. \n",
      "Branch Insurance (Branch) had goals for its internal development teams that were as ambitious as its efforts to provide uniquely simple insurance policies to its customers. The startup wanted to take an all-in approach to serverless architecture using Amazon Web Services (AWS) to make its infrastructure scalable, accelerate developer training, and simplify deployments. \n",
      "  Contact Sales \n",
      "Ρусский\n",
      " 3%\n",
      "عربي\n",
      "中文 (简体)\n",
      "Organizations of all sizes across all industries are transforming their businesses and delivering on their missions every day using AWS. Contact our experts and start your own AWS journey today.\n",
      "“Building a product on AWS is like doing it on ‘easy mode’ because there’s so much that’s simplified by using managed services,” says Emison. “We just write business logic and interfaces. That’s the great benefit of using AWS.” \n",
      "           2022 \n",
      " Overview\n",
      "Building a product on AWS is like doing it on ‘easy mode’ because there’s so much that’s simplified by using managed services. We just write business logic and interfaces. That’s the great benefit of using AWS.” \n",
      " 28%\n",
      "Customer Stories / Financial Services \n",
      " Amazon Cognito\n",
      " Improving Hiring Diversity and Accelerating App Development on AWS with Branch Insurance\n",
      "Branch Insurance is an insurance technology startup that provides simple insurance policies and comprehensive bundles to customers in 33 US states. The company was founded in 2017 in Columbus, Ohio. \n",
      "English\n",
      "Learn how Branch Insurance accelerated app development using AWS AppSync. \n",
      "more female engineers than the industry average\n",
      "Deutsch\n",
      " 10%\n",
      "Branch uses AWS AppSync as the foundation for its backend infrastructure and API service. AWS AppSync receives all the requests from the company’s website and mobile app, filters out malicious requests, makes sure each request is properly formatted, and finally initiates the proper business logic. The company also manages the authorization flow using libraries from AWS Amplify, open-source client libraries that developers can use to build cloud-powered mobile and web apps. “Branch’s entire backend, including all business logic and transactional data, runs on AWS AppSync,” says Emison. “By connecting AWS AppSync to AWS Amplify, the amount we have to deal with operations is extremely minimal.” \n",
      "Outcome | Building Products on 'Easy Mode' Using AWS Services\n",
      "Tiếng Việt\n",
      "Solution | Using AWS AppSync Accelerated App Development Cycles by 6 Months for Branch\n",
      "Italiano\n",
      "ไทย\n",
      "Branch uses the scalability of Amazon DynamoDB, a key-value and document database that delivers single-digit millisecond performance at virtually any scale, to handle as much traffic as it needs. Meanwhile, the startup stores all member information on Amazon Cognito, which businesses can use to add sign-up, sign-in, and access control to web and mobile apps quickly and easily. Branch has made user authentication effortless by using AWS AppSync to route each user login request to Amazon Cognito. “One of the magical parts of AWS AppSync is how well it connects to Amazon Cognito to automatically respond to authentication requests,” says Emison. \n",
      "Türkçe\n",
      "In just 3 years, Branch launched four insurance products—home, auto, renters, and umbrella insurance—in 33 US states. And the company did that with fewer than 20 full-time developers. As it continues to grow and hire new developers through its custom boot camp, it plans even more innovative features. \n",
      "Joe Emison Co-Founder and Chief Technology Officer \n",
      "Learn more »\n",
      "AWS Amplify is a complete solution that lets frontend web and mobile developers easily build, ship, and host full-stack applications on AWS, with the flexibility to leverage the breadth of AWS services as use cases evolve. No cloud expertise needed.  Learn more »\n",
      "Português\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: How can I use Lambda?</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs_text = [retrieved_file]\n",
    "context = \"\\nExtracted documents:\\n\"\n",
    "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
    "\n",
    "final_prompt = RAG_PROMPT_TEMPLATE.format(question=user_query, context=context)\n",
    "\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9b8b3a4-c8ed-4df9-baf4-bc7c8c9f6cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is a serverless compute service offered by Amazon Web Services (AWS). With Lambda, you can run code without provisioning or managing servers, making it a flexible and cost-effective option for processing large amounts of data, automating tasks, or responding to events. Here are some ways you can use Lambda:\n",
      "\n",
      "1. Process data: You can use Lambda to process large volumes of data without having to manage servers. For example, you could use Lambda to extract insights from log files, transform data between formats, or perform batch computations.\n",
      "\n",
      "2. Automate tasks: Lambda allows you to automate repetitive tasks, such as sending email notifications, generating reports, or triggering workflows. By automating these tasks, you can free up resources and reduce manual errors.\n",
      "\n",
      "3. Respond to events: Lambda can be triggered by events from various AWS services, such as Amazon S3 object creations, Amazon Kinesis data streams, or Amazon DynamoDB table updates. This enables you to build event-driven architectures that respond quickly and efficiently to user actions, sensor readings, or other events.\n",
      "\n",
      "4. Enhance real-time applications: Lambda can be integrated into real-time applications to provide low-latency responses. For instance, you could use Lambda to perform complex calculations or machine learning algorithms in real-time, or to generate dynamic content for websites or mobile apps.\n",
      "\n",
      "5. Build microservices: Lambda can be used to build small, independent services that can be scaled and deployed independently. This allows you to build more agile and flexible systems that can adapt to changing requirements.\n",
      "\n",
      "Overall, Lambda provides a powerful and flexible way to run code without having to manage servers, making it a popular choice for a wide range of use cases. Whether you're looking to process data, automate tasks, respond to events, enhance real-time applications, or build microservices, Lambda can help you achieve your goals.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "answer = llm(final_prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579538c8-7ccb-4a15-ab9d-3d3d05befec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chroma",
   "language": "python",
   "name": "chroma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
